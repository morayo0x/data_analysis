{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---|||\n",
    "# Pandas  Introduction \n",
    "\n",
    "It is a Python library used for data manipulation, cleaning and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The core data structure in pandas are Series (column like), and Dataframe(tabular like)\n",
    "---|||\n",
    "\n",
    "**Series**: one dimensional array-like object containing\n",
    "-  sequence of values, **P**\n",
    "-  an associated array of data labels, called its **index**\n",
    "\n",
    "> By default, the index ranges from 0 to the len(P) - 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/haiti/Haiti.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(file_path).loc[[3, 4,5], [\"Serial\", \"CATEGORY\", \"INCIDENT DATE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the associated indices\n",
    "pd.Series([5, 10, 111, 4, 3, 5, 6, 10, 4]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series with modified index, using its index parameter\n",
    "\n",
    "s = pd.Series([10, 20, 30, 40], index=['i', 'j', 'k', 'l'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the index of a given series using the index attribute\n",
    "\n",
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "##### The index of a Series can be used to select data corresponding to the index\n",
    "\n",
    "They act as index to the data sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['k'], s['i']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NumPy-like operations can be used to manipulate a Series object\n",
    "\n",
    "The index remains unchanged, after the operation(s) is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query if the series contains a given index\n",
    "\n",
    "'j' in s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A good mental model is to think of a Series object as a dictionary of keys and values\n",
    "\n",
    "- the index are the keys\n",
    "- the data are the values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some states and their corresponding capitals in Nigeria\n",
    "sdata = {'lagos': 'ikeja', 'ogun': 'abeokuta', 'adamawa': 'lafia'}\n",
    "\n",
    "# create a series object from the data\n",
    "s = pd.Series(sdata)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index\n",
    "\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query if an index is contained in the series\n",
    "\n",
    "'lagos' in s, 'fct' in s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "\n",
    "#### Alter the indices of a Series in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['l', 'o', 'a']\n",
    "\n",
    "# change the indices to index\n",
    "s.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Using the Dictionary to create the series will sort the data based on the keys\n",
    "\n",
    "This can be overriden by passing the same keys, and in whatever order to the index keyword\n",
    "\n",
    "> adding a key that doesn't belong in the dictionary will result in the key having a NAN value (a.k.a missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more indices than data, results in NAN values\n",
    "\n",
    "# some states and their corresponding capitals in Nigeria\n",
    "sdata = {'lagos': 'ikeja', 'ogun': 'abeokuta', 'adamawa': 'lafia'}\n",
    "\n",
    "# using the keys to order the values\n",
    "s = pd.Series(sdata, index=['lagos', 'adamawa', 'ogun'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a key that is not in the dictionary => 'fct\n",
    "# will add the key, but its value will benan\n",
    "\n",
    "\n",
    "s = pd.Series(sdata, index=['ogun', 'fct', 'adamawa', 'lagos'])\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### **isnull** and **notnull** method as a way of detecting missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index with missing data in a series\n",
    "\n",
    "s.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index without missing data in the series\n",
    "\n",
    "s.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the query formats (functions and instance method) are equivalent\n",
    "\n",
    "\n",
    "(\n",
    "    pd.notnull(s) == s.notnull(),\n",
    "    \n",
    "    pd.isnull(s) == s.isnull()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "##### Arithmetic Operations on series with similar keys \n",
    "\n",
    "When performing arithmetic operations on different series with similar keys, the keys are used to align the data before the operation is performed element wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = {'i': 11, 'j': 33, 'k': 23}\n",
    "bdata = {'a': 100, 'j': 23, 'b': 73, 'k': 1000} # keys j, k are in adata\n",
    "\n",
    "s1 = pd.Series(adata)\n",
    "s2 = pd.Series(bdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that not all the keys are the same\n",
    "\n",
    "# additional keys thar are not present in either index(es) ...\n",
    "# wi;; return nan values\n",
    "\n",
    "s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|^|\n",
    "\n",
    "Notice that keys that doesn't match have NAN values returned\n",
    "\n",
    "---\n",
    "---|||\n",
    "#### Naming a Series \n",
    "\n",
    "It is possible to name a series object using the name attribute of kwarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(sdata, name='States and Capital in Nigeria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name using its index attributes\n",
    "\n",
    "s.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "# Dataframe\n",
    "\n",
    "The other core pandas object is the DataFrame representing a tabular-like data (like excel spreadsheet). It contains\n",
    "\n",
    "- ordered collections of columns; each column can contain different data type\n",
    "- a row and column index\n",
    " \n",
    "A good mental model is to think of Dataframe as a dictionary containing\n",
    "\n",
    "- **keys**: representing the columns, and its column index\n",
    "-\n",
    "- **value**:  Series object such that\n",
    "  -  the keys of the series represent the row index\n",
    "  - the values in the series represent the data keyed by its row and column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe\n",
    "\n",
    "data = {'states': ['lagos', 'fct', 'ondo', 'oyo', 'plateau'], 'capital': ['ikeja', 'abuja', 'akure', 'ibadan', 'jos']}\n",
    "\n",
    "# the row index will automatically default to a number, \n",
    "# if we had used the dictionary as is.\n",
    "# but we pass one in the intialisation\n",
    "\n",
    "df = pd.DataFrame(data, index=['i', 'j', 'k', 'l', 'm'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe by passing list\n",
    "# and we can specify the column index...\n",
    "# in the order we want them to appear\n",
    "\n",
    "df = pd.DataFrame(\n",
    "  [('lagos', 'ikeja', 'SW'),\n",
    "   ('fct', 'abuja', 'NC'), \n",
    "   ('ondo', 'akure', 'SW'),\n",
    "   ('oyo', 'ibadan', 'SW'),\n",
    "   ('plateau', 'jos', 'SS')],\n",
    "  columns=['states', 'capitals', 'geographic_region'], index=['a', 'b', 'c', 'd', 'e']\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we passed this directly, then the columns will be ... \n",
    "# ordered based on the keys - (capital, geographic_region, states)\n",
    "\n",
    "data = {\n",
    "    'states': ['lagos', 'fct', 'ondo', 'oyo', 'plateau'],\n",
    "    'capital': ['ikeja', 'abuja', 'akure', 'ibadan', 'jos'],\n",
    "    'geographic_region': ['SW', 'NC', 'SW', 'SW', 'SS']\n",
    "    }\n",
    "\n",
    "# notice the order of the columns indices (geographic.., states, capital)\n",
    "\n",
    "# also notice that the population index in columns ... \n",
    "# is not contained in the data, so its values will be nan\n",
    "\n",
    "df = pd.DataFrame(data, columns=['geographic_region', 'states', 'capital', 'population'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### **Head** or **Tail** Selecting the top or last few elements\n",
    "\n",
    "We can select the first few elements in the beginning or end of the dataframe using the **head** and **tail** method.\n",
    "\n",
    "By default they return the first or last five rows in the dataframe, however, we can pass-in a number to indicate the number of rows that should be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first n values of a dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column index using the column attributes\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "\n",
    "# Indexing a Dataframe\n",
    "\n",
    "Remember that the keys to  the dataframe are its columns index.\n",
    "\n",
    "When the dataframe object is indexed by the column name, a series containing the row index and its corresponding data is returned.\n",
    "\n",
    "Indexing can be carried out in two ways; \n",
    "- **dictionary indexing**: as key \n",
    "- **attribute indexing**: using the name of the column\n",
    "\n",
    "> the dictionary indexing format is more general, as it can also be used with column index with *space* in their name, which would have other_wise be invalid using attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the data in the capital -> a series \n",
    "\n",
    "df['capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using attribute index\n",
    "\n",
    "df.geographic_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the population column\n",
    "\n",
    "df.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign values to the population column\n",
    "\n",
    "df.population = [20, 10, 3, 4, 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember broadcasting?\n",
    "\n",
    "df.population = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "\n",
    "#### Adding a new series to an existing dataframe object\n",
    "\n",
    "Add a new column then;  add a series to a new column in the dataframe\n",
    "\n",
    "Satisfy the following\n",
    "\n",
    "- The length of the series data must match the those in the dataframe\n",
    "- The index length of the series must match those in the dataframe, \n",
    "- the index names,that matches those in the dataframe will be aligned\n",
    "- the index name that doesn't match will be NAN\n",
    "\n",
    "\n",
    "> Note, if the index length, those of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the row index names\n",
    "\n",
    "df.index = ['one', 'two', 'three', 'four', 'five']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a series\n",
    "\n",
    "\n",
    "# the max length of the series must match those of the dataframe\n",
    "\n",
    "# the row index, 'five' is not on the new series index ... \n",
    "# hence the corresponding value will be nan\n",
    "\n",
    "# there is no 'not-good' index in the data frame, ... \n",
    "# hence its values will not be aligned\n",
    "\n",
    "s = pd.Series(\n",
    "    data=['no', 'yes', 'yes', 'yes', 'bad'], \n",
    "    index=['two', 'one', 'four', 'three', 'not-good']\n",
    "    )\n",
    "\n",
    "# add a new column to the dataframe\n",
    "# note this can only be created using dictionary key indexing\n",
    "# as using attribute indexing will not work\n",
    "\n",
    "df['Visited'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the series to the visited column\n",
    "\n",
    "# notice that the 'not-good' column doesn't match\n",
    "\n",
    "df.Visited = s\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Deleting a column from a dataframe\n",
    "\n",
    "Using the **del** keyword followed by the column selection from the dataframe will delete the column from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Visited']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---||| \n",
    "\n",
    "#### Swapping Columns and Rows with transpose\n",
    "\n",
    "Using the **transpose function** or **T attribute** will:\n",
    "\n",
    "- swap rows to columns\n",
    "- columns to rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "\n",
    "### Creating a new Dataframe from an existing Dataframe\n",
    "\n",
    "By using an existing dataframe object, one can create a new dataframe.\n",
    "\n",
    "IF the index key is also specified, then\n",
    "\n",
    "- any index of the previous dataframe added to this new index, will have its column data in the new data frame\n",
    "\n",
    "- new index will automatically be assigned nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only want the data in 'one, five and three' in the new dataframe\n",
    "\n",
    "# in the new index added, 'ten, nine' will be assigned nan \n",
    "\n",
    "df2 = pd.DataFrame(df, index=['one', 'ten', 'five', 'nine', 'three'])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the name attributes of the index and column of a dataframe\n",
    "\n",
    "df2.columns.name = 'States in Nigeria Info'\n",
    "df2.index.name = \"Numbering\"\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the values in a dataframe\n",
    "# the data are returned along the columns axis\n",
    "\n",
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "\n",
    "### Index Object\n",
    "\n",
    "This is a pandas object that holds the values of\n",
    "- a Series row index \n",
    "- a Dataframe's columns or row index A\n",
    "\n",
    "The Index Obeject is;\n",
    "\n",
    "- It is immutable \n",
    "- it can be shared among other data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulatiing a Series using its index object\n",
    "\n",
    "s = pd.Series(\n",
    "    data=['Mo', 'Usman', 'Kolawole'],\n",
    "    index=['a', 'b', 'c']\n",
    "    )\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index object\n",
    "\n",
    "ind = s.index\n",
    "\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index object are immutable\n",
    "\n",
    "ind[0] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create an index object\n",
    "\n",
    "ind = pd.Index(data=['l', 'm', 'n', 'p'])\n",
    "\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the new index object in a series\n",
    "\n",
    "s = pd.Series(np.arange(4), index=ind)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2 = ['l', 'm', 'n', 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember the difference between (==) and (is)?\n",
    "\n",
    "# compares element wise; remember vectorization?\n",
    "s.index == ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that they are the same object in memory \n",
    "\n",
    "s.index is ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index is ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Index Object as a container for Duplicate Object\n",
    "\n",
    "Since Index Object are immutable, they are similar to a fixed-set in Python, and support Set logic. But unlike Python Sets, they can contain duplicate values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two pandas object\n",
    "\n",
    "ind1 = pd.Index(['a', 'b', 'c', 'd', 'm', 'f', 'g', 'l'],)\n",
    "ind2 = pd.Index(['l', 'm', 'b', 'p', 'a', 'h', 'q', 'r'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply set logic to both\n",
    "\n",
    "# concatenate two Index objects to create a new one\n",
    "\n",
    "ind3 = ind2.append(ind1)\n",
    "\n",
    "ind3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the difference between two set A - B\n",
    "# this is remove all the elements of B that is also in A,  from A\n",
    "\n",
    "ind4 = ind3.difference(ind2)\n",
    "\n",
    "ind4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the union of two or more\n",
    "\n",
    "# remember this is set logic, so duplicates will not be allowed\n",
    "# but an index object itself can contain duplicate values\n",
    "\n",
    "ind5 = ind1.union(ind2)\n",
    "\n",
    "ind5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Re-indexing a Series \n",
    "\n",
    "The **reindex** method allows creating a new Series object, with the data of the old series **aligned** to a new index (if the index of the data in the old series are elements in the new index).\n",
    "\n",
    "> the data in the new index will be ordered based on how they are passed in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series\n",
    "\n",
    "s = pd.Series(\n",
    "    data=np.arange(8),\n",
    "    index=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "    )\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index using the reindex method\n",
    "\n",
    "# note there are new index values present, \n",
    "# so, index in **s** will be aligned to its data in the new series ...\n",
    "# and new index values will be assigned NAN values\n",
    "\n",
    "s.reindex(['a', 'i', 'j', 'k', 'b', 'l', 'm', 'c', 'n', 'p', 'd', 'q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Filling the NAN values in the **reindex** method\n",
    "\n",
    "When both old and new index values are passed as elements in the reindex method,\n",
    "the new index values will by default be **aligned** to NAN values. To fill this NAN values, one can pass the method of filling the NAN values.\n",
    "\n",
    "**Methods**\n",
    "\n",
    "- ffill: fill the NAN values with the last valid data before it,\n",
    "- bfill: fill the NAN with the first valid data that comes after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the same series, from above\n",
    "\n",
    "s.reindex(\n",
    "    index=['a', 'i' , 'b', 'j', 'c', 'k', 'd', 'e'],\n",
    "    method='ffill'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### NumPy UFunc and Mappings \n",
    "\n",
    "Remember UFuncs are numpy functions that apply an operation to each element of an ndarray, through broadcasting.\n",
    "\n",
    "In pandas, ufuncs can also be applied to pandas dataframe and series objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(24).reshape((6 , 4)))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sqrt ufunc of the table\n",
    "\n",
    "np.sqrt(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Apply Mapping Method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(1, 10))\n",
    "df = pd.DataFrame(np.arange(36).reshape(9, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  lambda x: x*x\n",
    "\n",
    "def g(x):\n",
    "    return pd.Series([x.min(), x.max()], index=['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(g, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### **applymap** method\n",
    "\n",
    "This is similar to apply, except that it applies the passed in function to each element in the dataframe, instead of applying it to a a series along a  specific axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((5, 6))\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = lambda x: '%.3f' %x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using apply will try to execute format on the axis (0, by default),\n",
    "# which should fail, because the format method except single values,\n",
    "# but the apply method will pass a series object to it\n",
    "\n",
    "df.apply(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to overcome this challenge, the applymap method is used\n",
    "\n",
    "df.applymap(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Sorting\n",
    "\n",
    "Sorting can be done in two ways:\n",
    "\n",
    "- **by values**: sort based on the value in the series or dataframe\n",
    "- **by index**: sort based on the index in the series OR based on the axis in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(1, 14, 2), index=['c', 'a', 'b', 'k', 'i', 'm', 'e'])\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by index in descending order\n",
    "\n",
    "s = s.sort_index(ascending=False)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by values in ascending\n",
    "\n",
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(1, 41, 3).reshape(7, 2), index=[3, 1, 7, 11, 32, 9, 0])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by index along axis = 1\n",
    "\n",
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by index along axis=0\n",
    "\n",
    "df.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by values along axis = 1, but a key must be specified\n",
    "\n",
    "df.sort_values(axis=1, by=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "# Chapter 6: Data Loading, Storage, and File Formats\n",
    "\n",
    "---|||\n",
    "### Loading/Reading of Data into a Dataframe Object\n",
    "\n",
    "The read_[type] is meant to convert data stored on disk to a Dataframe object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading a csv formatted data\n",
    "\n",
    "file_path = \"../datasets/Employees.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index column to Unnamed\n",
    "df = df.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove index name\n",
    "df.index.name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this multiple operations could be done directly when loading the file\n",
    "\n",
    "df = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "# Using **read_table** as a general method for loading text data\n",
    "\n",
    "While *read_csv* is specific to CSV formatted files, one can use *read_table*, and indicate how the data is formatted in an optional seperator key (sep).\n",
    "\n",
    "The seperator between data points for CSV-formatted file is a comma (,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use read_tables to open the Employee CSV data\n",
    "\n",
    "df = pd.read_table(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the format method in the seperator\n",
    "# remember the index column\n",
    "\n",
    "df = pd.read_table(file_path, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/babynames/yob1881.txt\"\n",
    "\n",
    "# suppose we don't know how the data is formatted, we use the read_table to peek\n",
    "\n",
    "df = pd.read_table(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is comma seperated, we use the read_csv file\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Using the header key\n",
    "\n",
    "\n",
    "It is used to specify whether the data has column names(header) associated with it. Whenever the header argument is still specified, then;\n",
    "\n",
    "- it value is either 0 or NONE\n",
    "- the default column names (0, 1, 2, 3, ...) based on the inferenced number of columns \n",
    "\n",
    "When the **names** key is specified, header must be specified with...\n",
    "\n",
    "- None: if column names are not present\n",
    "- 0: if they are present, but will be renamed (using names=[val1, val2, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something is amiss, the column names are part of the data\n",
    "# so we specify that the header (=> column names) is/are absent\n",
    "\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Setting the column names\n",
    "\n",
    "This can be achieved by passing a values to the **names** optional parameter in the read_csv method.\n",
    "\n",
    "There are implications if the length of the passed values exceed those in the data file. In this case, the name is added and populated with NAN values\n",
    "\n",
    "If the length of the passed values were less than those in the data file, then the the columns not accounted for are used to index the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be even more pragmatic, by specify the names we want\n",
    "# instead of using the default integer column indexing\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, names=['Name', 'Sex', 'Count'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/haiti/Haiti.csv\"\n",
    "\n",
    "# peek into the data\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of each columns of the dataframe\n",
    "\n",
    "df.count() \n",
    "\n",
    "# observe that the total length is 3593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the observation using the shape\n",
    "\n",
    "df.shape\n",
    "\n",
    "# its true; there are 3593 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the serial number a numbering format or special?\n",
    "\n",
    "# sort by index\n",
    "df.sort_values(by='Serial').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values of serial to start from 1, by subtracting 3\n",
    "\n",
    "# since we have a dataframe, and we want to apply and operation on...\n",
    "# each values in the Serial column, we use the map method\n",
    "\n",
    "# f = lambda x: x - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Serial = df.loc[:, 'Serial'] - 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex by Serial\n",
    "\n",
    "df.set_index('Serial', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an interesting data set\n",
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "\n",
    "# peek\n",
    "pd.read_table(file_path).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- the file has no header: set header to [name, year, genre]\n",
    "- we have three seperator :: to get the title and genre, () to get the year\n",
    "- we should replace the |, with something better , a space\n",
    "\n",
    "- the index of the data should be the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    file_path,\n",
    "    header=None,\n",
    "    names=['num', \"title\", \"year\", \"genre\", ''],\n",
    "    sep='(\\d+)::([^:]+)\\s\\((\\d+)\\)::(.*)',\n",
    "    engine='python',\n",
    "    keep_default_na=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "## Handling Missing Values \n",
    "\n",
    "It is possible to pass a string or sequence of strings, as values to the **na_values** key, which would marks any occurence of the string(s) as missing values (NAN, NA...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets set any Abel and Echo as sentinel value\n",
    "\n",
    "df = pd.read_csv(\"../datasets/Employees.csv\", na_values=['Able', 'Echo'])\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index\n",
    "\n",
    "df.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename index to empty \n",
    "df.rename_axis(index=\"\", inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### **na_values** for all or specific column(s)\n",
    "\n",
    "It is possible to specify that when a given data, as specified in the **value(s)** passed to the **na_values** key, then the data would be marked as sentinel i.e. the data would be marked as missing if any is found in the dataframe.\n",
    "\n",
    "It is also possible to specify that we want the matches in specific columns by passing a dictionary, containing a **key-value** pair to **na_values**, such that;\n",
    "\n",
    "- the key is the specific column name where we want to mark a certain data as sentinel\n",
    "\n",
    "- the value(s) is/are the data to mark as sentinel in the specified column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could have set the sentinel by selecting the specific column\n",
    "\n",
    "# lets set any Abel and Echo as sentinel value in the Name column\n",
    "#and all the values less than four (4) in the YearOfService column\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../datasets/Employees.csv\", \n",
    "    na_values={\n",
    "        'Name': ['Able', 'Echo'],\n",
    "        'YearOfService': [0, 1, 2, 3]       # values less than 4\n",
    "        },\n",
    "\n",
    "    # when names is specified, header must be specified with...\n",
    "    #   None: if column names are not present\n",
    "    #   0: if they are present, but will be renamed (using names=[])\n",
    "    header=0, # this allows us to specify no column\n",
    "    names= [\"\", \"Department\", \"Name\", \"YearOfService\"], # rename column\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "df.sort_values(by=['Name'], ascending=True).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Converter Optional Parameter\n",
    "\n",
    "This is a **read_csv, and read_table** optional parameter, that take a dictionary as value.\n",
    "\n",
    "Its purpose is to apply a **function/mapping f** specified as value to a **key representing the column name, that the function should apply the mapping** to every values in the specified column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    \"../datasets/a.txt\",\n",
    "    header=0,\n",
    "    names=[\"Deparment\", \"Name\", \"YearOfService\"],\n",
    "    sep=','\n",
    "    # index_col=0\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the observation above, lets change the NAN values in Name to 'MO'abs\n",
    "\n",
    "f = lambda x: ('Mo' if not x else x )\n",
    "# def f(x):\n",
    "    # if x\n",
    "df = pd.read_table(\n",
    "    \"../datasets/a.txt\",\n",
    "    header=0,\n",
    "    names=[\"Deparment\", \"Name\", \"YearOfService\"],\n",
    "    sep=',',\n",
    "    converters={'Name': f}\n",
    "    # index_col=0\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Reading Text Files in Pieces\n",
    "\n",
    "It is optimal, when reading data in large files, to read the data from the file in small pieces OR iterate through smaller chunks of the file\n",
    "\n",
    "One way this can be achieved is to specify the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the display to more compact format\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "\n",
    "# take a look at the resulting dataframe for example\n",
    "df = pd.read_table(\n",
    "    file_path,\n",
    "    header=None,\n",
    "    names=['num', \"title\", \"year\", \"genre\", ''],\n",
    "    sep='(\\d+)::([^:]+)\\s\\((\\d+)\\)::(.*)',\n",
    "    engine='python',\n",
    "    keep_default_na=False,\n",
    ")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3883 rows.\n",
    "\n",
    "Suppose it was very large, then it would take a lot longer to parse the entire data into the dataframe. One way to avoid this is to specify the **number of rows** we want from the file.\n",
    "\n",
    "By passing the **nrows** keys, the read_[format] will stop when it reaches the number of rows value specified. This is especially useful when one wants to quickly examine data in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of reading the entire file, we could specify the number of rows\n",
    "\n",
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "\n",
    "df = pd.read_table(\n",
    "    file_path,\n",
    "    header=None,\n",
    "    names=['num', \"title\", \"year\", \"genre\", ''],\n",
    "    sep='(\\d+)::([^:]+)\\s\\((\\d+)\\)::(.*)',\n",
    "    engine='python',\n",
    "    keep_default_na=False,\n",
    "    nrows=3\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Reading in chunks, by specifying the chunksize\n",
    "\n",
    "When the chunksize value is specified, an iterator over the chunks of data in the file is returned.\n",
    "\n",
    "Here, if the **chunksize == p**, then p amount of rows will be returned everytime we call **next** on the iterator (or we iterate using for loop), until, there are no more data to iterate over\n",
    "\n",
    "More interestingly, we can call the **get_chunks(size=val)** method, and specify a certain **val**, over the iterator returned, to\n",
    "\n",
    "- read less than the value of rows that would have been returned in a given iteration,  **if val < p**\n",
    "\n",
    "- read more than the value of rows that would have been returned in a given iteration, **if val > p**\n",
    "\n",
    "- read a given number of rows from a given iteration, based on the value of the specified size in the **get_chunks** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "\n",
    "# specify the chunksize to get an iterator\n",
    "\n",
    "chunk = pd.read_table(\n",
    "    file_path,\n",
    "    header=None,\n",
    "    names=['num', \"title\", \"year\", \"genre\", ''],\n",
    "    sep='(\\d+)::([^:]+)\\s\\((\\d+)\\)::(.*)',\n",
    "    engine='python',\n",
    "    keep_default_na=False,\n",
    "    chunksize=20\n",
    ")\n",
    "\n",
    "# in this iteration get the firs 20 rows\n",
    "next(chunk)\n",
    "\n",
    "# in this iteration, we get 22 rows; more than the chunksize specified\n",
    "print(chunk.get_chunk(size=22).shape)\n",
    "\n",
    "# in this iteration, we get the default chunksize specfied; 20\n",
    "print((next(chunk).shape))\n",
    "\n",
    "# in this iteration, we get 10 rows; less than the chunksize specified\n",
    "print(chunk.get_chunk(size=10).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "\n",
    "# specify the chunksize to get an iterator\n",
    "\n",
    "chunk = pd.read_table(\n",
    "    file_path,\n",
    "    header=None,\n",
    "    names=['num', \"title\", \"year\", \"genre\", ''],\n",
    "    sep='(\\d+)::([^:]+)\\s\\((\\d+)\\)::(.*)',\n",
    "    engine='python',\n",
    "    keep_default_na=False,\n",
    "    chunksize=10\n",
    ")\n",
    "\n",
    "# print the number of iterations it takes to read the entire file\n",
    "count = 0\n",
    "tot_rows = 0\n",
    "for piece  in chunk:\n",
    "    count += 1\n",
    "    tot_rows += piece.shape[0]\n",
    "    # print((piece.shape))\n",
    "\n",
    "'It took {0} iterations to read {1} number of rows'.format(count,  tot_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Writing Data To Text Format\n",
    "\n",
    "Using the **to_[format]**, we can save a dataframe data to disk based on the format specified\n",
    "\n",
    "\n",
    "dataframe.to_[format]([name.[format])\n",
    "\n",
    "\n",
    "- dataframe.to_excel([name.xlsl]): to excel format\n",
    "- dataframe.to_csv([name.csv]): to csv formatted\n",
    "- dataframe.to_json([name.json]): to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/Employees.csv\"\n",
    "\n",
    "df = pd.read_csv(\"../datasets/Employees.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to json; the record format omit the index \n",
    "\n",
    "df.to_json(\"employee.json\", \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv fomat, \n",
    "# but instead of the delimeter being comma, we use |\n",
    "\n",
    "df.to_csv(\"employee.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe the following data\n",
    "file_path = \"a.txt\"\n",
    "\n",
    "# since it is a .txt file, we use the read_table format\n",
    "# actually, we could have used a read_csv, since we know it is comma seperated\n",
    "\n",
    "df = pd.read_table(file_path, sep=',', index_col=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "There are missing values in the Name column, to replace this, missing values with another value, we could have used the **converter** method while reading the file.\n",
    "\n",
    "However, we want to save this data to disk, and replace any missing values with **another name**.\n",
    "\n",
    "To achieve the above, we pass the **value** to **na_rep** key. This value will  stand in for the missing values in the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"employee_NULL_for_NA.csv\", sep='|', na_rep=\"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could also remove the column labels by passing a header as false\n",
    "df.to_csv(\"employee_NULL_for_NA_w-o_header.csv\", sep='|', na_rep=\"NULL\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could also remove the index by passing an index key as false\n",
    "df.to_csv(\"employee_NULL_for_NA_w-o_header_w-o_index.csv\", sep='|', na_rep=\"NULL\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of writing the output to a file, by passing the file name,\n",
    "# we could output the result into standard output, which will just print the result\n",
    "\n",
    "# get the stdout\n",
    "from sys import stdout\n",
    "\n",
    "df.to_csv(stdout, sep='|', na_rep=\"NULL\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also indicate which columns we are interested in\n",
    "\n",
    "# we could also remove the index by passing an index key as false\n",
    "df.to_csv(stdout, sep='|', na_rep=\"NULL\", index=False, columns=[\"Department\", \"YearOfService\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Binary Data Formats\n",
    "\n",
    "One can take data in a different format and store it in binary format, in a process known as serialization\n",
    "\n",
    "The reverse is known as deserialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a csv file and save it in binary format\n",
    "\n",
    "f = lambda x: \"NULL\" if not x else x\n",
    "\n",
    "df = pd.read_table(\"a.txt\", index_col=['Unnamed: 0'], sep=',', converters={'Name': f})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it to binary format\n",
    "\n",
    "df_bin = df.to_pickle(\"employee_NULL_w-o_header_to_binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the binary file\n",
    "\n",
    "df = pd.read_pickle(\"employee_NULL_w-o_header_to_binary\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Storage Formats\n",
    "\n",
    "HDF5: Hierachical Data Format\n",
    "\n",
    "This is a file format used for **storing large quantities** of scientific array data. \n",
    "\n",
    "An HDF5 file can store multiple datasets, and metadata as a key-value pair. Interestingly, it supports the compression of those file, using **a variety of compression modes**, so that data with repeated pattern are stored efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store a dataframe in HDF5 format\n",
    "\n",
    "# create the dataframe\n",
    "df = pd.DataFrame({'a': np.random.randn(100)})\n",
    "\n",
    "# store as hdf\n",
    "store = pd.HDFStore('data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframe\n",
    "\n",
    "store['obj1'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['obj1_col'] = df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the df\n",
    "\n",
    "store['obj1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreive the data in col a\n",
    "\n",
    "store['obj1_col']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Storage Schema\n",
    "\n",
    "Two schema (i.e. mode of storing data) are supported by HDF5Store;\n",
    "\n",
    "- fixed: fast, but doen't support query operations\n",
    "\n",
    "- table: slow, but supports query operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'b': np.random.randn(40), 'e': np.random.randn(40)})\n",
    "\n",
    "store.put('obj2', value=df2, format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, if storage schema is \"fixed, then this query operation will fail\n",
    "store.select('obj2', where=['index >= 10 and index <= 15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the storage\n",
    "\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm close\n",
    "\n",
    "store['obj1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the same operation using read_hdf5, and to_hddf. \n",
    "a = np.arange(20).reshape((10, 2))\n",
    "\n",
    "df  = pd.DataFrame(a, columns=['a', 'b'])\n",
    "\n",
    "df.to_hdf('rdata.h5', 'obj', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf('rdata.h5', 'obj', where= ['index >=3', 'columns = a' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "# Chapter 7: Data Cleaning and Preparation\n",
    "\n",
    "> Note: cleaning and preparing data should be done within the context of the analysis of the data, how the data is collected\n",
    "\n",
    "**Steps Involved in Cleaning and Preparing Data for Analysis**\n",
    "\n",
    "- **Filtering**:\n",
    "\n",
    "    - duplicates\n",
    "    - missing values\n",
    "    - badly represented string values\n",
    "    - detecting outliers\n",
    "\n",
    "- **Transformation**:\n",
    "    \n",
    "    - mapping data to new form\n",
    "    - replacing data \n",
    "    - transforming badly represented string values\n",
    "    - renaming indexes (rows and column index)\n",
    "\n",
    "Cleaning involves removing data-points that will have adverse effect on the kind of analysis we want to perform on the data. This involve;\n",
    "\n",
    "- missing data\n",
    "- duplicates fata\n",
    "- badly processed data (e.g. strings that contains special characters)\n",
    "\n",
    "Preparation on the other hands comes after cleaning. It involves processing the cleaned data to a form that is suitable for the analysis to be be performed. This includes;\n",
    "\n",
    "- joining\n",
    "- grouping\n",
    "\n",
    "\n",
    "---|||\n",
    "### Querying A Series or Dataframe for Missing Data\n",
    "\n",
    "- isnull: returns an array of boolean with True specified for sentinel value\n",
    "- notnull: returns an array of boolean with False specified for sentinel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan as NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'a': [1, NA, 3, 6, 9, NA],\n",
    "    'b': [2, 4, NA, NA, 8, 10],\n",
    "    'c': [NA, NA, 10, NA, 20, NA ]\n",
    "}\n",
    "\n",
    "# create a dataframe\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the isnull to check for all the sentinel values in column a\n",
    "\n",
    "df['a'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the non-null values in column b\n",
    "\n",
    "df['b'].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Filtering Missing Data\n",
    "\n",
    "**dropna**\n",
    "\n",
    "This by default drop any rows containing a sentinel value.\n",
    "\n",
    "\n",
    "Customization:\n",
    "\n",
    "- axis: 0 (rows), 1(columns)\n",
    "- how: \"all\" or \"any\"\n",
    "- thresh: indicates the number of non-sentinel values required to NOT drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the rows containing missing data\n",
    "\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column containing non-sentinel values\n",
    "\n",
    "df['d'] = 33\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of remove rows by default, remove columns containing sentinels\n",
    "\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of non-sentinel values as condition for dropping a row\n",
    "\n",
    "# only remove rows that contains less than 2 non-sentinel values\n",
    "\n",
    "df.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use axis 1\n",
    "\n",
    "df.dropna(axis=1, thresh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new index to the dataframe\n",
    "\n",
    "df = pd.DataFrame(df, index=[0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify that only rows where all values are sentinel be dropped\n",
    "\n",
    "df.dropna(how=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an e column containing missing values\n",
    "\n",
    "df = pd.DataFrame(df, columns=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify that only columns where all values are sentinel be dropped \n",
    "\n",
    "df.dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Filling Missing Data\n",
    "\n",
    "The consideration here is to replace the missing data with another value, so as to avoid discarding non-sentinel data from the series or dataframe\n",
    "\n",
    "**fillna**: used to fill sentinel values in a dataframe\n",
    "\n",
    "Customization:\n",
    "\n",
    "method: \"ffill\", \"bfill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all sentinel values with a 0\n",
    "\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can chose how to fill sentinel values by columns\n",
    "\n",
    "df.fillna({'a': 22, 'b': 111, 'c': 999, 'd': 1000, 'e': 333})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can chose to fill sentinel values in each columns by the last valid value before the sentinel in that column\n",
    "\n",
    "df.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also specify the number of values we want to forward fill (ffill)\n",
    "\n",
    "# we only fill one sentinel value that follow each other consecutively using the last valid value\n",
    "\n",
    "df.fillna(method=\"ffill\", limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used bfill to fill the sentinel values\n",
    "# using the first valid value after the sentinel value\n",
    "\n",
    "df.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Data Transformation\n",
    "\n",
    "This involves transforming the data to produce a standardized version of the data that can be used in analysis. Transforming the data includes;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"a1\": [3, 4, 6, 3, 4, 6, 3], \"a2\": [3, 4, 6 ,3, 4, 6, 3], \"a3\": [1, 4, 6, 1 ,4, 6, 5]}\n",
    "\n",
    "# create the dataframe with only four unique index \n",
    "\n",
    "df = pd.DataFrame(data, index=[\"one-1\", \"two-1\", \"three-1\", \"one-2\", \"two-2\", \"three-2\", \"four-1\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates data in all the columns\n",
    "# note, the index is not considered in duplicated operation by default\n",
    "\n",
    "df.duplicated()\n",
    "\n",
    "# indicates that 5th and 6th rows are duplicated\n",
    "\n",
    "# ---\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select duplicates based on a subset of columns\n",
    "\n",
    "# check for duplicates in a1 and a2\n",
    "\n",
    "df.duplicated(subset=[\"a1\", \"a2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select duplicates based on a subset of columns\n",
    "\n",
    "# check for duplicates in a1 and a3\n",
    "\n",
    "df.duplicated(subset=[\"a1\", \"a3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select duplicates based on a subset of columns\n",
    "\n",
    "# check for duplicates in a2 and a3\n",
    "\n",
    "df.duplicated(subset=[\"a2\", \"a3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Filtering out Duplicated Data\n",
    "\n",
    "**drop_duplicates**\n",
    "\n",
    "By default, it drops the duplicated rows; here the elements in all the columns must match. This can be customized to choose a subset of the columns that will be considered before dropping the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated data, whose values match in all the columns\n",
    "# this method does not remove both the original and duplicates... \n",
    "# it only removes the duplicated data\n",
    "\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can customize this to remove both the orginal and duplicates\n",
    "\n",
    "df.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could instead keep the last duplicates\n",
    "\n",
    "df.drop_duplicates(keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we could keep the first which is the default\n",
    "\n",
    "df.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use the columns subset to drop duplicates\n",
    "\n",
    "# any duplicate in a1, and a2, should be used to drop the duplicates\n",
    "\n",
    "df.drop_duplicates(subset=[\"a1\", \"a2\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any duplicate in a2, and a3, should be used to drop the duplicates\n",
    "\n",
    "df.drop_duplicates(subset=[\"a2\", \"a3\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Transformation Using A Function\n",
    "\n",
    "Instead of dropping missing data, and losing other valid datapoints with it, we may wish to transorm the sentinel values to another value that won't have adverse effect on the analysis. \n",
    "\n",
    "A function or mapping is specified to transform data in a series or columns in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "data = {\n",
    "    \"country\": ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'],\n",
    "    \"population\": [20, 10 ,1, 3, 1.5, 4, 2, 9]\n",
    "}\n",
    "\n",
    "file_path = \"a.txt\"\n",
    "\n",
    "df = pd.read_table(file_path, sep=',', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all the na values with \"null\"\n",
    "\n",
    "df.fillna({\"Name\": \"null\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let standardize the data so that all the data in \n",
    "# department and name are in uppercase\n",
    "\n",
    "df[\"Department\"] = df.loc[:, [\"Department\"]].applymap(lambda x: x.upper())\n",
    "df[\"Name\"] = df.loc[:, [\"Name\"]].applymap(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Stringifying a Series\n",
    "\n",
    "This will convert all the data in the series to  their string representation. When this succeed, string methods can be applied on each data in the series.\n",
    "\n",
    "> Note: this applies only to a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could have achieved the same thing as above by\n",
    "# first converting it to a string format, and then use strings method\n",
    "\n",
    "df.loc[:, \"Department\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Series Map method\n",
    "\n",
    "This accepts a dictionary or function that takes a datapoint and map it to another value; IF the argument is a:\n",
    "\n",
    "**Dictionary**\n",
    "\n",
    "==series.map([dictionary={key:value}])==\n",
    "\n",
    "Then it would map each **key** that is contained in the **series instance** to a new **value**. IF the key is however not present in the series, it would be mapped to nan.\n",
    "\n",
    "**Function**\n",
    "\n",
    "==series.map(function)==\n",
    "\n",
    "Then the function would be apply to each datapoint to produce the corresponding output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Department\"] = df[\"Department\"].map(lambda datapoint: datapoint.lower())\n",
    "df[\"Name\"] = df[\"Name\"].map(lambda datapoint: datapoint.lower())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets map marketing - sales, engineering - tech and accounting - finance\n",
    "\n",
    "df[\"Department\"].map({\"marketing\": \"sales\", \"engineering\": \"tech\", \"accounting\": \"finance\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could have done the above using a custom function\n",
    "\n",
    "def department_mapping(datapoint: str):\n",
    "    # accounting\n",
    "    if datapoint.startswith('a'):\n",
    "        return \"finance\"\n",
    "\n",
    "    # engineering\n",
    "    if datapoint.startswith(\"e\"):\n",
    "        return \"tech\"\n",
    "\n",
    "    # marketing\n",
    "    # since we know our datapoint falls into these three categories,\n",
    "    # ... and that there are no sentinels in this column, ... \n",
    "    # we know that marketing is the only category that hasn't been checked. \n",
    "    return \"sales\"\n",
    "    # if datapoint.startswith(\"m\"):\n",
    "        # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the funtion\n",
    "df[\"Department\"].map(department_mapping).str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Data Replacement\n",
    "\n",
    "This generally involves substituting another value for sentinels and non-sentinels datapoints.\n",
    "\n",
    "This is more flexible than using the **fillna** method\n",
    "\n",
    "**replace(to_replace, value(opt))**\n",
    "\n",
    "**Single Replacement**\n",
    "\n",
    "- **datapoint** to a **value**\n",
    "\n",
    "**Multiple Replacement**\n",
    "\n",
    "- a **list of datapoints** to a **list of values**: both lists length must match\n",
    "\n",
    "- we can use a dictionary such that:\n",
    "    - **keys** specifies the datapoints to replace, and\n",
    "    - **values** specfies what to replace the datapoints with\n",
    "\n",
    "    > if this is intended, then the **value optional parameter** would not be passed\n",
    "\n",
    "    IF the value parameter is however specified, this imply that, we want to search a dataframe having its column as the **keys** specified, and to search for any datapoints equal to the **value** specified, and replace those datapoints to the one given in the **list of values specified in the optional value parameter.\n",
    "\n",
    "- we can also use a dictionary that contains another dictionary such that;\n",
    "\n",
    "    - the outer dictionary is such that its;\n",
    "        - **keys**: represent the columns to perform the replacement operations\n",
    "        \n",
    "        - **values**: is the inner dictionary containing;\n",
    "            - **keys** representing the datapoints to replace\n",
    "            - **values** representing what to replace the datapoints with\n",
    "\n",
    "    > Here also, the **value optional parameter** will not be specified\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use replace to perform the same mapping above\n",
    "\n",
    "df.replace({\n",
    "    \"Department\": \n",
    "        {\n",
    "            \"accounting\": \"finance\",\n",
    "            \"marketing\": \"sales\",\n",
    "            \"engineering\": \"tech\"\n",
    "        },\n",
    "    \"Name\": {\n",
    "            \"null\": \"Mo\"\n",
    "        }\n",
    "        \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using another dictionary format\n",
    "\n",
    "df.replace({\"Name\": \"null\" }, value= \"Xango\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list\n",
    "\n",
    "df.replace(\n",
    "    [\"null\", 'engineering', 'accounting', 'marketing'],\n",
    "    [\"Xango\", \"Techers\", \"Salers\", \"Financers\"]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Renaming Axis Indexes\n",
    "\n",
    "The axis indexes can be replaced by calling the map method an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the index to uppercase\n",
    "\n",
    "to_uppercase = lambda x: x.upper()  \n",
    "\n",
    "df.columns = df.columns.map(to_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the rename method instead creates a copy\n",
    "\n",
    "df.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a dictionary instead\n",
    "# remember the columns are already in uppercase, hence making the keys in uppercase\n",
    "df.rename(columns={\n",
    "    \"department\".upper(): \"Department\",\n",
    "    \"name\".upper(): \"Name\",\n",
    "    \"yearofservice\".upper(): \"YearOfService\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "# Discretizing and Binning Data\n",
    "\n",
    "This allows separating data into a given discrete value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### **cut** function\n",
    "\n",
    "Takes a one-dimensional array and a segment that determines how the data would be divided.\n",
    "\n",
    "It returns a series with its values as the segment where each datapoints falls in\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- if an array is passed to cut for binning, a **Categorical** object is returned, and we can access the index of the categories (codes) and categories by using the attributes directly\n",
    "\n",
    "- if a series is passed, then a series is returned. To access the codes and and categories attribut, we must first convert the returned series to a categorical object using the **cat** attribute. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the year of service into bins 1 to 2, 3 to 7, 8 to 12, and 13 to higher values\n",
    "\n",
    "bins = [0, 2, 7, 12, 20]\n",
    "\n",
    "category = pd.cut(df[\"YEAROFSERVICE\"], bins)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the categories each datapoints falls into\n",
    "\n",
    "category.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the categories are close to the right and open to the left; i.e. (., .]\n",
    "\n",
    "This can be changed by specfiying the **right** parameter in the cut instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of each category the data points falls into\n",
    "\n",
    "# 0 -> (0, 2], \n",
    "# 1 -> (2, 7]\n",
    "# 2 -> (7, 12]\n",
    "# 3 -> (12, 20]\n",
    "category.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the year of service into bins 1 to 2, 3 to 7, 8 to 12, and 13 to higher values\n",
    "\n",
    "# have a closed interval at the leftm and open to the right\n",
    "bins = [0, 2, 7, 12, 20]\n",
    "\n",
    "category = pd.cut(df[\"YEAROFSERVICE\"], bins, right=False)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get how many values falls in each segments using value_counts\n",
    "\n",
    "pd.value_counts(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass an identifier to identify each segments\n",
    "\n",
    "This is achieved using the **label optional parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the year of service into bins 1 to 2, 3 to 7, 8 to 12, and 13 to higher values\n",
    "\n",
    "bins = [0, 2, 7, 12, 20]\n",
    "\n",
    "# since we have four segment, we must pass a list having four label\n",
    "\n",
    "category = pd.cut(\n",
    "    df[\"YEAROFSERVICE\"],\n",
    "  bins, \n",
    "    labels=[\n",
    "        \"> 0 and <= 2\",\n",
    "        \"> 2 and <= 7\",\n",
    "        \"> 7 and <= 12\",\n",
    "        \">12 and <=20\"\n",
    "    ])\n",
    "\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the category\n",
    "\n",
    "category.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can pass an integer for bin, and it will  compute equal length bins\n",
    "\n",
    "# divide the year of service into bins 4 to higher values\n",
    "\n",
    "category = pd.cut(df[\"YEAROFSERVICE\"], bins=4)\n",
    "category.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrain the floating point values to a given precision\n",
    "# by passing a precision parameter\n",
    "\n",
    "data = np.random.random(20)\n",
    "\n",
    "category = pd.cut(data, bins=4, precision=3)\n",
    "category.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Binning Using Quantiles using **qcut**\n",
    "\n",
    "\n",
    "In this case, it will bin the datapoints into the specified integers, where:\n",
    "\n",
    "- 2 ==> into two\n",
    "- 4 ==> into quartiles\n",
    "- 100 ==> percentiles\n",
    "\n",
    "e.t.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the YearOf Service into percentiles\n",
    "\n",
    "category = pd.qcut(df[\"YEAROFSERVICE\"], 100, duplicates=\"drop\")\n",
    "\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many categories\n",
    "\n",
    "category.cat.categories.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Detecting and Filtering Outliers\n",
    "\n",
    "**sign method(it is a numpy method)** : takes a dataframe or series, and produce\n",
    "-  (+1) if the element is postive\n",
    "\n",
    "-  (-1) if the element is postive\n",
    "\n",
    "    and return the corresponding series or dataframe\n",
    "\n",
    "**sample method**: takes a series or dataframe, and generate a random sample based on the number passed as argument. Additionally, the replace boolean keyword can modified such that IF set to;\n",
    "\n",
    "- True: the sample will be generated **with replacement**: the sample size can be greater than the population size\n",
    "\n",
    "- False: the sample will be generated **without replacement**: the sample size must be less than the population size\n",
    "\n",
    "**take method**: takes an array of row index, and produce the series or data frame with the passed row indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sign(pd.Series([-3, 4, -7, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(20).reshape((5, 4))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['a', 'b', 'c', 'd'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign\n",
    "\n",
    "np.sign(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take method\n",
    "\n",
    "df.take([0, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 3 samples without replacement: \n",
    "# in this case the sample(n=3) cannot be greater than the population (total n = 5)\n",
    "\n",
    "df.sample(n=3, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 10 samples with replacement\n",
    "# in this case the sample(n=10) can be greater than the population (total n = 5)\n",
    "\n",
    "df.sample(n=10, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Computing Indicator/Dummy Variables\n",
    "\n",
    "Converting a **categorical variable** into a **dummy or indicator matrix** using the categorial variable: with 0 indicating absent, and 1 indicating present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'key': ['i', 'j', 'k', 'j', 'k', 'i', 'p', 'j', 'p'],\n",
    "     'data': range(9)\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the indicator matrix\n",
    "\n",
    "# this creates a matrix, with 0 indicating absent, and 1 indicating present\n",
    "\n",
    "pd.get_dummies(df[\"key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a prefix to the categorical variable\n",
    "\n",
    "dummy_matrix = pd.get_dummies(df['key'], prefix='category')\n",
    "\n",
    "dummy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummy = df[['data']].join(dummy_matrix)\n",
    "df_with_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator matrix using the movielens dataset\n",
    "\n",
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "\n",
    "# movies = pd.read_table(file_path, header=None, names=[\"movie_id\", \"title\", \"genre\"], sep=\"::\")\n",
    "movies = pd.read_table(file_path, header=None, names=[\"movie_id\", \"title\", \"genre\"])\n",
    "\n",
    "movies.iloc[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/pydata_datasets/movielens/movies.dat\"\n",
    "f = lambda x: int(x) if not np.nan else x\n",
    "mov = pd.read_table(\n",
    "    filepath_or_buffer=file_path,\n",
    "    sep=r\"(\\d*)::\\s?(.+)\\((\\d*)\\)?::(.*|\\s)$\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"num\", \"movie_id\", \"title\", \"year\", \"genre_1\", \"\"],\n",
    "    converters={\"year\": f, \"genre_2\": g}\n",
    ")\n",
    "\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_cleaned = mov.dropna(how=\"all\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = mov.genre_1.str.strip()\n",
    "gen = gen.str.split(\"|\")\n",
    "\n",
    "gen.str.join(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique genres\n",
    "\n",
    "genre = df[\"genre\"].str.strip()\n",
    "genre = genre.str.split('|')\n",
    "\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the result into a single list\n",
    "all_genre = []\n",
    "\n",
    "for x in genre:\n",
    "    all_genre.extend(x)\n",
    "len(all_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique ones\n",
    "\n",
    "uniq_genre = pd.unique(all_genre)\n",
    "\n",
    "uniq_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the indicator matrixe\n",
    "\n",
    "# remember, the categorical variable will be the columns of the matrix, and\n",
    "# the rows of the matrix will correspond to that of the entire dataset\n",
    "\n",
    "# create a zero_matrix, that will have the shape of the resulting indicator matrix\n",
    "zero_matrix = np.zeros((len(movies), len(uniq_genre)))\n",
    "\n",
    "# create the dataframe, with 0's, but the columns are the categorical variable (uniq_genre)\n",
    "dummies = pd.DataFrame(zero_matrix, columns=uniq_genre)\n",
    "dumies_copy = dummies.copy()\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, gen in enumerate(movies.genre):\n",
    "    indices = dummies.columns.get_indexer(gen.split('|'))\n",
    "    dummies.iloc[i, indices] = 1\n",
    "\n",
    "# this is the same as above\n",
    "# for i, genre in enumerate(movies.genre):\n",
    "#     genre = genre.split('|')\n",
    "\n",
    "#     dumies_copy.loc[i, genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_indicator = movies.join(dummies.add_prefix(\"Genre_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_indicator.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to iterate through the movies, genre, \n",
    "# and if a row has a given genre in its values, \n",
    "# we should add a 1 to the the column containing the genre\n",
    "\n",
    "movies.head()\n",
    "\n",
    "genre = movies.genre\n",
    "genre.str.contains('Animation')\n",
    "\n",
    "np.where(cond, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumies_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### String Manipulation & Regular Expression\n",
    "\n",
    "**Important String Methods**\n",
    "\n",
    "- *startswith and endswith*\n",
    "- *join*\n",
    "- *find*: returns -1 if it fails to find the requested data\n",
    "- *strip, rstrip and lstrip*: trim whitespaces, including newlines(\\n)\n",
    "- *replace*\n",
    "- *split*\n",
    "\n",
    "---|||\n",
    "#### Regular Expression\n",
    "\n",
    "- **Compiling a regular exepression**:\n",
    "\n",
    "Suppose we want to apply a regular expression method on different strings for the purpose of processing the strings, then it is better, for efficiency, to compile the regular expression, before calling the method on the strings. \n",
    "\n",
    "\n",
    "- **Regex Methods**\n",
    "\n",
    "0. **compile**: this allows us to compile the regex, and possible flags, so that we can utilize it with different methods (as given below) by saving us the compilation step. Consequently, it saves us of CPU cycles.\n",
    "\n",
    "1. **search**: returns an object that can be queried for the *starting* and *ending* position of the first match.\n",
    "\n",
    "2. **match**: it does the same thing as *search* above. But it starts matching at the beginning of the string, **unlike *search that scans through the string to find its first match**\n",
    "\n",
    "3. **findall**: this returns all the matches\n",
    "\n",
    "4. **split**: similar to Python native split method on strings, although this is now within the context of regex.\n",
    "\n",
    "5. **sub**: returns a new string with the matched occurences replaced with a new strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regular expression library\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"  foo      bar\\t  baz     \\tqux\"\n",
    "\n",
    "# compile the regular expression \"\\s+\", so we can use different methods on it\n",
    "regex = re.compile('\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the position where the first match occurs\n",
    "\n",
    "regex.search(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on matches\n",
    "\n",
    "regex.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.match(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the matches\n",
    "\n",
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.sub(\"REPLACEMENT-TEXT\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Vectorized String Functions In Pandas\n",
    "\n",
    "Pandas allows the use of native python string methods, and regex methods, through \"stringifying\" a column using the **str** attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com','Rob': 'rob@gmail.com', 'Wes': np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\\\.([A-Z]{2,4})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str.findall(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = data.str.match(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "# Chapter 9: Plotting and Visualization\n",
    "\n",
    "**Importance of Visualization in Data Analysis**\n",
    "\n",
    "- Identify Outliers\n",
    "- Identify a possible need for Data Trasnformation\n",
    "- Generating ideas for model\n",
    "- Building interactive visualization for the web\n",
    "\n",
    "**matplotlib**: is a python package for creating publication-quality plots  (mostly two-dimensional visualization), and these plots can also be exported to different formats such as PDF, SVG, JPG, PNG, GIF,e.t.c.\n",
    "\n",
    "**seaborn**: \"is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(10)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple plot of datapoints\n",
    "\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### The Figure Object\n",
    "\n",
    "All plots in **matplotlib** resides within a **Figure** object. \n",
    "\n",
    "A mental model to reason about Figure is to think of it as the *canvas* that we plot on.\n",
    "\n",
    "It is possible to have multiple plots on a Figure object using **add_subplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new figure object\n",
    "fig =plt.figure()\n",
    "\n",
    "# create a (sub)plot on the figure object\n",
    "\n",
    "# the add_subplot argument takes three argument: nrows, ncols, and the index\n",
    "\n",
    "# 2 x 2 figure object => 4 plots in total, this will be the 1st plot\n",
    "\n",
    "ax1 = fig.add_subplot(2, 2, 1)  \n",
    "\n",
    "# 2nd plot\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "\n",
    "# 3rd plot\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "# 4th plot\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "plt.plot(data) # automatically plot on the last subplot\n",
    "\n",
    "# we explicitly specified the first one with a style option (k--)\n",
    "ax1.plot(np.random.randn(50).cumsum(), 'k--') # k-- => black dashed line \n",
    "\n",
    "# selecting the third, and specifying a style option (b-)\n",
    "ax3.plot(np.random.randn(50).cumsum(), 'b-') # the b- => blue and solid line\n",
    "\n",
    "\n",
    "# plot a histogram \n",
    "\n",
    "_ = ax2.hist(\n",
    "    np.random.randn(100),\n",
    "    bins=20,\n",
    "    color='r',\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another convenient method, for creating subplots on a figure object is by using the **subplots** method, which will in turn **create a new figure object, and returns a NumPy array containing the created subplot objects**.\n",
    "\n",
    "**Arguments to The *subplot* method**\n",
    "\n",
    "- nrows: how many rows we want on the figure object\n",
    "- ncols: how many columns we want on the figure object\n",
    "- sharex: a boolean that determines whether all the subplots must use the same x-axis ticks (values)\n",
    "- sharey: a boolean that determines whether all the subplots must use the same y-axis ticks (values)\n",
    "- figsize: used to set the width and height of the figure object\n",
    "- alpha: used the modify the transparency of the plot with respect to the background color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned array, containing the axes objects, can easily be indexed to create subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 9 (3 x 3) subplots object on a figure\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, sharex=None, figsize=(10,6))\n",
    "\n",
    "# we use the tight_layout to avoid overlaps between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# create a plot on the axes in the second row, second column\n",
    "axes[1, 1].plot(np.random.randn(100).cumsum())\n",
    "\n",
    "# a plot of histograms on the remaining axes\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i == 1 and j == 1:\n",
    "            continue\n",
    "        axes[i, j].hist(np.random.randn(10000), bins=1000, color='g', alpha=0.5)\n",
    "\n",
    "# change the spaces between axes such that they almost overlap\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Colors, Markers, and Line Styles\n",
    "\n",
    "These are represented as keyword arguments:\n",
    "\n",
    "**color**: either hexcode or abbreviations\n",
    "\n",
    "- green: g\n",
    "- red: r\n",
    "- blue: b\n",
    "- black: k, and many more\n",
    "\n",
    "**linestyle**: the style used to fit the data points\n",
    "\n",
    "- dashed = --\n",
    "- star = *\n",
    "- solid = -\n",
    "- dashdot = -.\n",
    "- dotted = :\n",
    "\n",
    "**markers**: use to highlight the actual data points in the plots, passed as abbreviation\n",
    "\n",
    "- o: circular\n",
    "- p: pentagon\n",
    "- d: diamond shaped\n",
    "- h: hexagon\n",
    "- x: cross\n",
    "- *: star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly specify the color, linestyle and marker\n",
    "plt.plot(randn(90).cumsum(), color='g', linestyle= ':', marker='o')\n",
    "\n",
    "# modify the labels on the x-axis\n",
    "plt.xticks(np.arange(-10, 110, 20), labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "\n",
    "# modify the scale of the x-axis\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same specification could be combined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(randn(50).cumsum(), 'g:o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In plots, the resulting line is fitted to the actual data, while the subsequents parts (i.e. between data points) are interpolated.\n",
    "\n",
    "It is possible to overide this interpolation using: \n",
    "\n",
    "- **drawstyle**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = randn(30).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data, 'r:o', label=\"Default\")\n",
    "\n",
    "plt.plot(data, 'b--o', drawstyle='steps-post', label='Steps-Post')\n",
    "\n",
    "plt.xticks(np.arange(0, 34, 2))\n",
    "\n",
    "# plt.xlim(0, 34)\n",
    "plt.legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labels**: this is a descriptive name given to a single plot\n",
    "\n",
    "**Legends** allows the identification and display of **labels** on the figure. Any single value or a combination of the following will determine the locations of the **label(s)**; [lower, upper, right, left, center].\n",
    "\n",
    "> Note: when a combination is used, then a space must seperate the values\n",
    "\n",
    "**ticks** is used to indicate the divisions on the axes: **xticks** and **yticks** \n",
    "\n",
    "**wspace and hspace**: this is used to modify the width and height between subplots in a Figure object\n",
    "\n",
    "**rotation**: used with **x(y)tickslabel** to determine if the labels should be rotated or not based on the rotation angle passed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "axes[0].plot(np.random.randn(25).cumsum(), \"m--o\", label=\"Gaussian-1\")\n",
    "axes[0].plot(np.random.randn(25).cumsum(), \"r-\", label=\"Gaussian-2\")\n",
    "axes[0].plot(np.random.randn(25).cumsum(), \"r:\", label=\"Gaussian-3\")\n",
    "axes[0].set_xticks(np.arange(0, 21, 5))\n",
    "axes[0].set_xticklabels([\"a\", \"b\", \"c\", \"d\", \"e\"], rotation=45, fontsize=\"small\")\n",
    "axes[0].set_title(\"Plot of Random Normally Distributed Numbers\")\n",
    "axes[0].set_xlabel(\"Checkers\")\n",
    "axes[0].legend(loc=\"best\")\n",
    "# axes[0].legend(loc=\"upper left\")\n",
    "\n",
    "# second plot with properties from a dictionary\n",
    "\n",
    "props = {\n",
    "    'title': \"Randomly Generated Number\",\n",
    "    'xlabel': \"Randoms\",\n",
    "    'ylabel': \"Y-Values\",\n",
    "    'xticklabels': ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight']\n",
    "}\n",
    "\n",
    "axes[1].plot(np.random.random(30).cumsum(), 'r-.x', label=\"Non-Gaussian\")\n",
    "axes[1].plot(np.random.randn(25).cumsum(), \"r:\", label=\"Gaussian\")\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "axes[1].set(**props)\n",
    "# axes[1].legend(loc=\"upper left\")\n",
    "axes[1].legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "\n",
    "ax1.plot(np.random.randn(1000).cumsum())\n",
    "\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "\n",
    "ax2.plot(np.random.randn(1000).cumsum())\n",
    "\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "ax3.plot(np.random.randn(1000).cumsum())\n",
    "\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "ax4.plot(np.random.randn(1000).cumsum())\n",
    "\n",
    "\n",
    "ax2.text(700, 8, \"Morayo Lol\", family=\"monospace\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../datasets/examples/spx.csv\"\n",
    "\n",
    "df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and annotate the closing S&P 500 index price, with important dates\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Annotation\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- **text**-*string*: represents the **label**, usually text, that will be used to annotate the specific (data)point.\n",
    "\n",
    "- **xy**-*tuple*: a tuple containing the coordinates of the points to be annotated.\n",
    "    It is important to note that based on the data type (e.g datetime, int, float e.t.c), one can **add a value to the corresponding y coordinate so that the label does not sit *directly* on the data point**. One can also do this to the x cordinate if necessary. \n",
    "\n",
    "- **xytext**-*tuple*: this perform the same operation as **xy** above, but unlike **xy**, **xytext** determines the **position of the *label* with respect to the identifier (or an arrow pointing to the annotated (data)point)**\n",
    "\n",
    "- **arrowprops**-*dict*: a mapping that determines the properties of the arrow identifying the (data)point to be annotated. One can specify the key-value pair for customizing the identifier:\n",
    "\n",
    "    - *facecolor*: color of the arrow\n",
    "    - *headwith*: specify the width of the arrow head\n",
    "    - *headlength*: specifies the length of the arrow head\n",
    "    - *width*: how wide the arrow body should be\n",
    "    - *horizontalalignment*: specifies the horizontal position of the label w.r.t the arrow identifier - *left, center, right*\n",
    "    - *verticalalignment*: specifies the vertical position of the label w.r.t the arrow identifier - *top, bottom, center, baseline, center_baseline*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the canvas\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "# add a sub-figure\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# get the data we need for plotting\n",
    "spx = df['SPX']\n",
    "\n",
    "# plot the spx data\n",
    "spx.plot(ax=ax, style='m-')\n",
    "\n",
    "# annotation data indicating the crisis year\n",
    "crisis_data = [\n",
    "    (datetime(2007, 10, 11), 'Peak of Bull Market'),\n",
    "    (datetime(2008, 3, 12), 'Bear Stearns Fails'),\n",
    "    (datetime(2008, 9, 15), 'Lehman Bankruptcy')\n",
    "]\n",
    "\n",
    "# use the crisis data with datetime as x and corresponding string as y to annotate\n",
    "for date, label in crisis_data:\n",
    "    ax.annotate(label, xy=(date, spx.asof(date) + 75),\n",
    "                xytext=(date, spx.asof(date) + 220),\n",
    "                arrowprops=dict(facecolor='black', headwidth=4, width=1, headlength=3),\n",
    "                horizontalalignment='left', verticalalignment='center')\n",
    "\n",
    "# zoom in on 2007 - 2010\n",
    "props = {\n",
    "    \"xlim\": ['1/1/2007', '1/1/2011'],\n",
    "    \"ylim\": [600, 1800],\n",
    "    \"title\": \"Important Dates in the 2008-2009 financial crisis\"\n",
    "}\n",
    "\n",
    "ax.set(**props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Shapes and Adding it to A Figure using **add_patch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(10)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "rect = plt.Rectangle((0.2, 0.7), width=0.3, height=0.2, rotation_point=(0.1, 0.4), color='m', alpha=0.3)\n",
    "\n",
    "circ = plt.Circle((0.7, 0.2), radius=0.1, color='g', alpha=0.3)\n",
    "\n",
    "pgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]], color='r', alpha=0.2)\n",
    "\n",
    "\n",
    "# add shapes to figure\n",
    "\n",
    "ax.add_patch(circ)\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(pgon)\n",
    "\n",
    "# save  fig\n",
    "\n",
    "plt.savefig('myplots.png', dpi=1000, bbox_inches='tight', facecolor='yellow', edgecolor='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Figures and Customization\n",
    "\n",
    "- **file-name** and **extension**: used in the file name;  pdf, png, jpeg, jpg, svg\n",
    "\n",
    "- **dpi**: this controls the resolution; the higher the value, the higher the resolution \n",
    "\n",
    "- **facecolor**: background color outside of subplots\n",
    "\n",
    "- **format**: explicit file format to use if not specified as the extension in file-name; pdf, svg, png e.t.c.\n",
    "\n",
    "- **bbox_inches**: portion of figure to save: 'tight' will trim the empty space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Matplotlib Configuration\n",
    "\n",
    "**matplotlib** can be globally configured, using the pyplot **rc** method\n",
    "\n",
    "pyplot.rc('what to configure', '[new configuration]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all figures to be of size 10 x 5\n",
    "\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "\n",
    "# configure the fonts\n",
    "\n",
    "plt.rc('font', family='monospace', weight='medium', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Line Plots\n",
    "\n",
    "Using the pandas instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas plot method, that uses matplotlib at the backend\n",
    "s.plot()\n",
    "\n",
    "# this is equivalent to:\n",
    "# plt.plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.randn(1000, 4).cumsum(1),\n",
    "    columns=['A', 'B', 'C', 'D'], # labels\n",
    "    index=np.arange(0, 10000, 10)) # xticks\n",
    "\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Bar Plots\n",
    "\n",
    "Horizontal and Vertical Bar plots:\n",
    "\n",
    "\n",
    "\n",
    "> Using a DataFrame to make a bar plot, groups the data points in each row together in a group in bars, side by side, for each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "data = pd.Series(np.random.rand(16), index=list('abcdefghijklmnop'))\n",
    "\n",
    "\n",
    "data.plot.bar(ax=axes[0], color='m', alpha=0.8)\n",
    "data.plot.barh(ax=axes[1], color='r', alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a dataframe\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(6, 4),\n",
    "                  index=['one', 'two', 'three', 'four', 'five', 'six'],\n",
    "                  columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack each group on each other\n",
    "\n",
    "df.plot.bar(stacked=True, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.barh(stacked=True, alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data visualization example using the tips datasets for customers patronizing a weekend **party club** containing the following columns\n",
    "\n",
    "- **total_bill**: the total amount (plus tips) paid by the customer(s)\n",
    "- **tip**: amount of tips paid by the customer(s). Note(this value is also added to the total_bill)\n",
    "- **smoker**: determines whether the customer(s) smokes or not.\n",
    "- **day**: identifies the day (Thursday, Friday, Saturday, Sunday).\n",
    "- **time**: identifies the time (Dinner, or Lunch)\n",
    "- **size**: the number of people on the given table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/examples/tips.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rc('figure', figsize=(10, 6), dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the number of customers based on days?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should take all the size corresponding to sun, thur, fri, and sat and sum their corresponding sizes\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Sun': np.where(df.day == 'Sun', df['size'], 0).cumsum().max(),\n",
    "    'Sat': np.where(df.day == 'Sat', df['size'], 0).cumsum().max(),\n",
    "    'Fri': np.where(df.day == 'Fri', df['size'], 0).cumsum().max(),\n",
    "    'Thur': np.where(df.day == 'Thur', df['size'], 0).cumsum().max()\n",
    "}\n",
    "\n",
    "sns.barplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare days where customers gave the highest number of tips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Sun': np.where(df.day == 'Sun', df['tip'], 0).cumsum().max(),\n",
    "    'Sat': np.where(df.day == 'Sat', df['tip'], 0).cumsum().max(),\n",
    "    'Fri': np.where(df.day == 'Fri', df['tip'], 0).cumsum().max(),\n",
    "    'Thur': np.where(df.day == 'Thur', df['tip'], 0).cumsum().max()\n",
    "}\n",
    "\n",
    "sns.barplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Crosstab\n",
    "\n",
    "Using the **class method** allows the tabulation of two *Series* object, usually with repitition. One of which will contain the column labels and the other, the row labels. The data points are then given as the number of occurences  of each (row, col) values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(np.array([0, 1, 1, 1, 2]))\n",
    "b = pd.Series(np.array(['a', 'b', 'a', 'b', 'c']))\n",
    "\n",
    "pd.crosstab(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_counts = pd.crosstab(df['day'], df['size'])\n",
    "\n",
    "party_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the parties  whose size are not large; 1 and 6\n",
    "\n",
    "party_counts = party_counts.loc[:, 2:5]\n",
    "\n",
    "party_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize each rows, such the it sums to 1\n",
    "\n",
    "p = party_counts.div(party_counts.sum(1), axis=0)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar plot of the result\n",
    "\n",
    "p.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tips_pct'] = df['tip'] / (df['total_bill'] - df['tip'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x='tips_pct', y='day', data=df, hue='time', orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Histograms and Density Plots\n",
    "\n",
    "A histogram gives a discretized display of value of frequency, in such a way that the datapoints are;\n",
    "\n",
    "- split into discrete size\n",
    "\n",
    "- evenly spaced bins\n",
    "\n",
    "and the number of data points in each bin is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/examples/tips.csv\"\n",
    "\n",
    "tip = pd.read_csv(file_path)\n",
    "\n",
    "tip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip['tip_pct'] = tip['tip'] / (tip['total_bill'] - tip['tip'])\n",
    "\n",
    "tip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(15, 10), dpi=800)\n",
    "plt.rc('font', family='monospace', weight='medium', size=12)\n",
    "plt.rc('axes', xmargin=0.05)\n",
    "plt.rc('grid', alpha=0.5, color='m', linewidth=0.7, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# tip['tip_pct'].plot.hist(bins=50)\n",
    "\n",
    "sns.histplot(tip['tip_pct'], bins=50, color='m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Density Plots\n",
    "\n",
    "While histogram discretizes the data, density plots makes the assumption that the data points are continuos, by approximatiing the data points with a continuos probability distribution, **that might have generated the data**.\n",
    "\n",
    "- Density plots are also known as *Kernel Density Estimate*.\n",
    "\n",
    "> it approximate the distribution as a mixure of **kernels** - simpler distribution like the normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1)\n",
    "\n",
    "tip['tip_pct'].plot.density(ax=ax[0])\n",
    "\n",
    "# using mixures of normal estimate\n",
    "tip['tip_pct'].plot.kde(ax=ax[1])\n",
    "\n",
    "# using seaborn\n",
    "sns.histplot(ax=ax[2], data=tip['tip_pct'], kde=True)\n",
    "\n",
    "\n",
    "sns.displot(ax=ax[3], data=tip['tip_pct'], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Scatter Plots\n",
    "\n",
    "This can be used to see the relationship between two variables using their data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/examples/macrodata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = pd.read_csv(file_path)\n",
    "\n",
    "macro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = macro[['cpi', 'm1', 'tbilrate', 'unemp']]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "\n",
    "trans_data = np.log(data).diff().dropna()\n",
    "\n",
    "\n",
    "trans_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "**regplot** allows one to;\n",
    "\n",
    "- a scatter plot of two variable\n",
    "- determine their line of best fit on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot and determine the line of best fit\n",
    "import seaborn as sns\n",
    "sns.regplot( data=trans_data, x='m1', y='unemp')\n",
    "\n",
    "plt.title('Changes in log %s versus log %s' % ('m1', 'unemp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Pair/Scatter Plot Matrix\n",
    "\n",
    "Allows plotting multiple scatter plots between group of variables. This is achieved using the **pairplot** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha':  0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Facet Grids and Categorical Data\n",
    "\n",
    "Unlike scatter plots where data is assumed to be continuos, **facets** grid visualization is used on data with many categorical variables. This is achieved using the **catplot**(instead of the deprecated **factorplot**) method\n",
    "\n",
    "In this settings, the \n",
    "\n",
    "- **col** option is used to specify the how the multiple plots should be constructed. IF the option has; say three categorical variables, then three plots based with each categorical variable in each columns will be created\n",
    "\n",
    "- **kind**: specify the type of plot, namely- **bar, strip, swarm, box, boxen, count, point, violin.**\n",
    "\n",
    "- **hue**: this is used to specify that a given axis (usually x) can be categorized into two or more seperate variable, in which case, the corresponding plots are plotted side-by-side.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/examples/tips.csv\"\n",
    "\n",
    "tip = pd.read_csv(file_path)\n",
    "\n",
    "tip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip['tip_pct'] = tip['tip'] / (tip['total_bill'] - tip['tip'])\n",
    "\n",
    "tip.time.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple bar charts with the day on the x-axis and tip percentage freq on y\n",
    "\n",
    "sns.catplot(x='day', y='tip_pct', hue='time', col='smoker', kind='bar', data=tip[tip.tip_pct < 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Chapter 8: Data Wrangling: Join, Combine, and Reshape\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Hierarchial Indexing\n",
    "\n",
    "This involves having more than one index levels on an axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.random.randn(9),\n",
    "                 index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[['a', 'b'], [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a label to the row index\n",
    "\n",
    "data.index.names = ['l', 'n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Form a Dataframe where one index level (the inner) is used as columns and the other index level (the outer) is the row using **unstack**.\n",
    "\n",
    "> By default, the outer-most index is used as the row- index. This can be changed using the level option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unstacked = data.unstack(level=1)\n",
    "\n",
    "\n",
    "data_unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the inner index to unstack\n",
    "\n",
    "data_unstacked_inner = data.unstack(level=0)\n",
    "\n",
    "\n",
    "data_unstacked_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack a dataframe so that the columns is used as another index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unstacked.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking the inner\n",
    "\n",
    "data_unstacked_inner.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the levels to achieve the original indexing\n",
    "\n",
    "data_unstacked_inner.stack().swaplevel('l', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(12).reshape(4, 3),\n",
    "                  index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                  columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = ['key1', 'key2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.names = ['state', 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Reordering and Sorting Levels\n",
    "\n",
    "This allows for rearrangement of the order of **levels** on an axis (using **swaplevel**) or the sorting of data by values in one specific level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.swaplevel('key2', 'key1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting using **sort_index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap levels and sort index\n",
    "\n",
    "df.swaplevel(0, 1).sort_index(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Summary Statistics By Level\n",
    "\n",
    "Summary statistics can be performed by aggregating data based on a specific index, through the level option.\n",
    "\n",
    "> Note: the groubby(level=?).? should be used instead of specifying the option in the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of this, used the one below\n",
    "\n",
    "# df.sum(level=1)\n",
    "\n",
    "df.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level='state', axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Indexing with a DataFrame Column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': [0, 1, 2, 0, 1, 2, 3]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index with the b and d columns\n",
    "\n",
    "df.set_index(['c' ,'b', 'd']).swaplevel('c', 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a new index using the colunns without dropping the indexing column(s)\n",
    "\n",
    "df2 = df.set_index(['c', 'b'], drop=False)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.set_index(['c', 'b'])\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset to an original indexing\n",
    "\n",
    "\n",
    "NOTE: We can use reset_index if the **drop** option is set to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "\n",
    "df3.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Combining and Merging Datasets\n",
    "\n",
    "Mechanism of combining Datasets\n",
    "\n",
    "- **merge (or join)**  method: connects rows in dataframes based on one or more keys.\n",
    "\n",
    "- **concat** method: concatenates (or stacks) objects together along an axis.\n",
    "\n",
    "- **combine_first**: *splice* overlapping data to fill in missing values in one object with values from another object.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Merge or Join\n",
    "\n",
    "Allows the combination of one or more datasets by linking rows using one or more keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': list('bbacaab'), 'data1': range(7)})\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the key to join on is not specified, then the overlapping column names will be used as keys\n",
    "\n",
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicity specify the key\n",
    "\n",
    "pd.merge(df1, df2, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that only values that are the same in the keys are used for the join operation. Values that are not the same will not appear in the result.\n",
    "\n",
    "> this is similar to using the **how='inner'** join keyword; which is the default\n",
    "\n",
    "##### This can be overidden by specifying **how** the data should be joined - **(left, right, inner, outer). The corresponding data without the same key value will be NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the left and right data\n",
    "\n",
    "pd.merge(df2, df1, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\n",
    "    'lkey': list('bbacaab'),\n",
    "    'data1': range(7)\n",
    "})\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'rkey': list('abd'),\n",
    "    'data2': range(3)\n",
    "})\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are no overlapping keys; what should happen? Error?\n",
    "\n",
    "pd.merge(df3, df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When there are no overlapping keys, then the **left_on** *AND* **right_on** options must be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Merge/Join Methods\n",
    "\n",
    "- **INNER**: join using the keys present in both datasets. Keys that are absent are omitted in the join operation. *This is the default*\n",
    "\n",
    "- **OUTER**: uses all the key combinations to perform the join operation. Here, any key not present in both datasets are *NOT* omitted in the result.\n",
    "\n",
    "- **LEFT**: uses *ALL* the keys on the LEFT dataset, even if  a specific key is not present in the RIGHT dataset, to perform the join operation.\n",
    "\n",
    "- **RIGHT**: uses *ALL* the keys on the RIGHT dataset, even if  a specific key is not present in the LEFT dataset, to perform the join operation.\n",
    "\n",
    "> The *indicator* option shows where the join operation is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the \"c\" key to be present in the resulting output\n",
    "\n",
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey', how='left', indicator='where')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join to make sure key 'd' is present in the result\n",
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey', how='right', indicator='where')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTER join uses all the key combinations to perform the join operation, while INNER (the default) join  uses only key that are both present in the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join \n",
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---||| Join Operations\n",
    "\n",
    "There are two ways data can be joined, based on the keys supplied;\n",
    "\n",
    "- **many-to-one**: where one or more of the left keys are repeated, *AND* the right keys are not. In this settings, the keys are only \n",
    "  > All the above join operation is a *many-to-one*; \n",
    "\n",
    "\n",
    "- **many-to-many**, one or more of the left *AND* right keys are repeated. In this case, the join operation is such that the cartesian product between keys that on the left and right is performed.\n",
    "\n",
    "E.g. If there are 4 keys on the left and 3 on the right labelled 'b', then the total combinations is 4 x 3 == 12.\n",
    "\n",
    "**Visually**: let the left keys and right be as follows;\n",
    "- left -> (b11, b12, b13, b14),\n",
    "- right ->  (b21, b22, b23)\n",
    "\n",
    "Combination would then be:\n",
    "\n",
    "- (b11, b21), (b11, b22), (b11, b23)\n",
    "- (b12, b21), (b12, b22), (b12, b23)\n",
    "- (b13, b21), (b13, b22), (b13, b23)\n",
    "- (b14, b21), (b14, b22), (b14, b23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two dataframe with keys repeated in both\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    data={\n",
    "        'key1': ['a', 'a', 'c', 'b', 'a', 'c', 'b', 'b', 'd', 'c', 'd'], \n",
    "        'data1': [2, 4, 5,1,6, 7, 9, 0, 1, 4, 10]})\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    data={'key2': ['a', 'e', 'c', 'b', 'a', 'f', 'b', 'k', 'd', 'c', 'e'],\n",
    "        'data2': [23, 49, 501 , 110.45, 603.2, 71.4, 90.1, 0.5, 100.3, 40.4, 20.5]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many-to-many join on key1 and key2\n",
    "\n",
    "pd.merge(left=df1, right=df2, left_on='key1', right_on='key2', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Joining on Multiple Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two dataframe with keys repeated in both\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    data={\n",
    "        'key1': ['b', 'c', 'a', 'b', 'a', 'c'], \n",
    "        'key2': ['foo', 'bar', 'foo', 'foo', 'bar', 'bar'], \n",
    "        'data1': [2, 4, 5, 7, 8, 0]\n",
    "    },\n",
    "    index=[\n",
    "      ['one', 'two', 'three', 'one', 'three', 'two'],\n",
    "      [1, 1, 1, 2, 2, 3]\n",
    "    ]  \n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    data={\n",
    "      'key1': ['c', 'a', 'b', 'a', 'k', 'c'],\n",
    "      'key2': ['bar', 'bar', 'foo', 'foo', 'bar', 'bar'], \n",
    "\n",
    "      'data2': [23, 71.4, 90.1, 100.3, 40.4, 20.5]\n",
    "    },\n",
    "    index=[\n",
    "      ['two', 'one', 'two', 'three', 'one', 'three'],\n",
    "      [1, 3, 2, 4, 2, 4]\n",
    "    ],\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join on multiple keys; inner by default\n",
    "\n",
    "pd.merge(left=df1, right=df2, on=['key1', 'key2'], indicator='where')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join, so that all keys in df1 appears\n",
    "\n",
    "pd.merge(left=df1, right=df2, on=['key1', 'key2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join, so that all keys in df2 appears\n",
    "\n",
    "pd.merge(left=df1, right=df2, on=['key1', 'key2'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join, so that all keys in df1 and df2 appears\n",
    "\n",
    "pd.merge(left=df1, right=df2, on=['key1', 'key2'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Join using **cross*\n",
    "\n",
    "This performs all possible combinations between the keys even if they are not the same. In other words, unlike many-to-many that performs all possible combination between keys that are the same in both dataset, using the **cross** option performs the combination both on same keys and otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join, so that all keys in df1 appears\n",
    "\n",
    "pd.merge(left=df1, right=df2, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can join on a single key=> 'key1\n",
    "\n",
    "pd.merge(left=df1, right=df2, on='key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change the suffixes 'x' and 'y'\n",
    "\n",
    "pd.merge(left=df1, right=df2, on='key1', suffixes=('__left', '__right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can join on a single key=> 'key2'\n",
    "\n",
    "pd.merge(left=df1, right=df2, on='key2', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change the suffixes 'x' and 'y'\n",
    "\n",
    "pd.merge(left=df1, right=df2, on='key2', suffixes=('_left', 'right'), indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Performance Consideration\n",
    "\n",
    "The **sort** and **copy** option in the **merge** method should be considered for performance purposes. \n",
    "\n",
    "- The sort option, performs the merge while sorting based on the keys used. For better performance, it is set to False, so that no sorting on the keys is performed on the resulting data strucuture. If sorting is required, and performance is not of consideration, then it should be set to **True**\n",
    "\n",
    "- The copy option copies data from the dataset to be merged into a new data structure which is then given as the output of the merge operation. By default also, while carefully considering data loss, it can be set to False; in which case, **data is not copied nut moved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the sort option default=> False\n",
    "\n",
    "pd.merge(df1,df2, on='key1',\n",
    "          suffixes=('__left', '__right'), indicator='where')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the sort option=> True\n",
    "\n",
    "pd.merge(df1, df2, on='key1', \n",
    "         suffixes=('__left', '__right'), indicator='where', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental performance; without sorting\n",
    "%timeit pd.merge(df1,df2, on='key1', suffixes=('__left', '__right'), indicator='where', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental performance; with sorting\n",
    "%timeit pd.merge(df1,df2, on='key1', suffixes=('__left', '__right'), indicator='where', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the copy option\n",
    "\n",
    "%timeit pd.merge(df1,df2, on='key1', suffixes=('__left', '__right'), indicator='where', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental performance; with sorting\n",
    "%timeit pd.merge(df1,df2, on='key1', suffixes=('__left', '__right'), indicator='where', copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2, on='key1', suffixes=('__left', '__right'), indicator='where', copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Merging on Index\n",
    "\n",
    "Instead of using the column labels as keys, the index is/are used as keys for the join operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['a', 'b', 'a', 'c', 'b', 'a'], 'value': range(6)})\n",
    "right = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the coulmn name 'key' in the left data, and the index column 'index', on the right data\n",
    "pd.merge(left= left, right=right, left_on='key', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using outer join\n",
    "\n",
    "pd.merge(left= left, right=right, left_on='key', right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefth = pd.DataFrame(\n",
    "  {\n",
    "    'key1': ['Ohio', 'Ohio', 'Ohio','Nevada', 'Nevada'],\n",
    "    'key2': [2000, 2001, 2002, 2001, 2002],\n",
    "    'data': np.arange(5.)})\n",
    "\n",
    "\n",
    "righth = pd.DataFrame(\n",
    "  data= np.arange(12).reshape((6, 2)),\n",
    "  index=[\n",
    "    ['Nevada', 'Nevada', 'Ohio', 'Ohio','Ohio', 'Ohio'],\n",
    "    [2001, 2000, 2000, 2000, 2001, 2002]\n",
    "  ],\n",
    "  columns=['event1', 'event2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "righth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=lefth, right=righth, left_on=['key1', 'key2'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=lefth, right=righth, left_on=['key1', 'key2'], right_index=True, how='outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Using the join method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "  data={\n",
    "    'key_a': ['one', 'three', 'two', 'three', 'one'],\n",
    "    'key_b': ['a', 'c', 4, 2, 1],\n",
    "    'data1':[11, 22, 33, 44, 55]\n",
    "    },\n",
    "  index=[\n",
    "    ['foo', 'bar', 'foo', 'foo', 'bar'],\n",
    "    ['a', 'b', 'b', 'a', 'c']\n",
    "  ]\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "  data={\n",
    "    'key_a': ['one', 'two', 'two', 'four', 'three'],\n",
    "    'key_b': ['a', 4, 'c', 2, 1],\n",
    "    'data1':[12, 23, 35, 46, 65]\n",
    "    },\n",
    "  index=[\n",
    "    ['two', 'one', 'three', 'two', 'one'],\n",
    "  ]\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index.names = ['ind_1', 'ind_2']\n",
    "df2.index.names = ['ind_1']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on 'key_a'\n",
    "\n",
    "pd.merge(df1, df2, on='key_a', how='inner', \n",
    "         indicator='where', copy=False, sort=False, suffixes=('---left', '---right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on multiple keys 'key_a' and 'key_b'\n",
    "\n",
    "pd.merge(df1, df2, on=['key_a', 'key_b'], \n",
    "         indicator='where', copy='False', suffixes=('-left', '-right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge using 'key_a' and the right_index\n",
    "\n",
    "pd.merge(df1, df2, left_on='key_a', right_index=True,\n",
    "          indicator='where', copy=False, suffixes=('--left', '--right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the join method\n",
    "\n",
    "df1.join(df2, on='key_a', how='outer', lsuffix='-left', rsuffix='-right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wenote that to use the join method, instead of merge, the dataframe must have the same index levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2, on=['key_a', 'key_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "  'key_a': ['a', 'b', 'a', 'c', 'b'],\n",
    "  'data1': [\"Kolawole\", \"Usman\", \"Ariyo\", \"25\", \"Male\"]\n",
    "}, index=['foo', 'foo', 'bar', 'foo', 'bar'])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "  'key_b': ['c', 'a', 'a', 'b', 'c'],\n",
    "  'data1': [\"Tohode\", \"Sunday\", \"Junior\", \"25\", \"Male\"]\n",
    "}, index=['foo', 'bar', 'bar', 'bar', 'foo'])\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "  'key_c': ['a', 'c', 'a', 'b', 'b'],\n",
    "  'data1': [\"Ogbonna\", \"Kelechi\", \"Elizabeth\", \"24\", \"Female\"]\n",
    "}, index=['bar', 'foo', 'bar', 'foo', 'bar'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the three dataframe\n",
    "\n",
    "df1.join([df2, df3], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Concatenation ALong Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate numpy arrays\n",
    "\n",
    "arr1 = np.arange(12).reshape(4, 3)\n",
    "arr2 = np.random.random(size=12).reshape(4, 3)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([arr1, arr2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([arr2, arr1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Pandas **concat** Function.\n",
    "\n",
    "Performs the same operation just like the numpy **concatenation** function. However, it does so with extra capabalities.\n",
    "\n",
    "- combine distinct elements or shared elements from objects(series or dataframe), if the objects are indexed differently on the other axes.\n",
    "\n",
    "- preserve data along the **concatenation** axis if need be.\n",
    "\n",
    "- identify which data belongs to which object in the resulting concatenated object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some simple examples\n",
    "\n",
    "s1 = pd.Series([0, 1], index=['a', 'b'])\n",
    "s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])\n",
    "s3 = pd.Series([5, 6], index=['f', 'g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By default, the concat function is along **axis==0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all the objects\n",
    "\n",
    "pd.concat([s1, s2, s3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the concatenation axis\n",
    "\n",
    "pd.concat([s1, s2, s3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### When there are no overlap laong the **other (i.e. not default)** axis of concatenation, the resulting concatenated object is similar to **\"outer join\", but of the indexes acting as keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat s1, s3 along the default axis\n",
    "\n",
    "s4 = pd.concat([s1, s3])\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat s1 and s4 along \"axis==1\"-> there are overlapping indexes now\n",
    "\n",
    "pd.concat([s1, s4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Specifying **join** Optional Parameter in **concat**\n",
    "\n",
    "Unlike **merge** that has five different ways on how objects should be joined throught the **how** method; \n",
    "\n",
    "- ***\"cross\", \"outer\", \"inner\", \"left\", and \"right\"***; where *inner* is the default, \n",
    "\n",
    "**concat** on the other hand has two, specified through the **join** keyword parameter; \n",
    "\n",
    "- ***\"outer\", \"inner\"***; where *outer* is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the outer default join method\n",
    "\n",
    "pd.concat([s1, s4], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using inner to join based on shared keys; remember indexes are the keys here \n",
    "\n",
    "pd.concat([s1, s4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note; in concat, the keys used to perform the concatenation operation are the **indexes**\n",
    "\n",
    "---\n",
    "---|||\n",
    "### Specifying **keys** Keyword Parameter\n",
    "\n",
    "This is used as an identifier for data belonging to each of the objects joined. \n",
    "\n",
    "Note that if say; **p** objects are passed for concatenation, then at most **p** *keys* should be passed to identify data belong to each object. However, \n",
    "\n",
    "- If less < **p** keys are passed then the resulting output of the concatenated object will be the same as the number of keys passed, and in the order of the passed in object.\n",
    "\n",
    "- If greater > **p** keys are passed, then the keys used will be based on the number of objects to be concatenated\n",
    "\n",
    "> By default, the keys will be along axis==0 if the axis is not specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed in 5 object and < 5 keys(==2)\n",
    "\n",
    "pd.concat([s1, s4, s1, s2, s3], keys=['one', 'two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed 5 objects and 5 keys\n",
    "\n",
    "pd.concat([s1, s4, s1, s2, s3], keys=['one', 'two', 'three', 'four', 'five'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed 5 objects and > 5 keys(==6)\n",
    "\n",
    "pd.concat([s1, s4, s1, s2, s3], keys=['one', 'two', 'three', 'four', 'five', 'six'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([s1, s2, s4], axis=0, keys=[\"ONE\", \"TWO\", \"THREE\"])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index to columns\n",
    "\n",
    "result.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the specified keys the column names\n",
    "\n",
    "pd.concat([s1, s2, s4], axis=1, keys=[\"ONE\", \"TWO\", \"THREE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above can be achieved by using a dictionary; as in\n",
    "# note we have specified the column names to be used\n",
    "\n",
    "pd.concat({\"ONE\": s1, \"TWO\": s2, \"THREE\": s4}, axis=1, names=[\"column_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can ignore the row index if it doesn't contain relevant data\n",
    "# using the ignore_index option\n",
    "\n",
    "df1 = pd.DataFrame(data= [[25, 45],[35, 70], [26, 456]], index=['a', 'b', 'c'], columns=[\"ONE\", \"TWO\"])\n",
    "df2 = pd.DataFrame(data= [[5, 90],[24, 0], [6, 6]], index=['d', 'e', 'f'], columns=[\"THREE\", \"FOUR\"])\n",
    "df3 = pd.DataFrame(data= [[103, 24],[16, 0]], index=['g', 'h'], columns=[\"FIVE\", \"SIX\"])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df2, df1])\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using inner join\n",
    "\n",
    "pd.concat([df1, df4], join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the indexes\n",
    "\n",
    "pd.concat([df1, df4], join='inner', ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the objects the column names; there are two levels now\n",
    "\n",
    "pd.concat([df1, df2], axis=1, keys=[\"level1\", \"level2\"], names=['column_name_1', 'column_label_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Combining Data with Overlap: **combine_first**\n",
    "\n",
    "This allows the combination of data that overlap fully or partly in such a way that the combination cannot be expressed as a **merge** or **concat** operation. It behaves as thought it is patching missing object in the calling  object using data in the passed object to the **combine_first** method.\n",
    "\n",
    "> In series, the **indexes** act as the key for overlap, while dataframe uses both the **indexes and columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(np.array([np.nan, 1, 3, 4, np.nan]), index=['a', 'b', 'c', 'd', 'e'])\n",
    "s2 = pd.Series(np.array([30, 10, np.nan, 40, np.nan]), index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the data such that the first overlapping data that is not null is used\n",
    "\n",
    "s1.combine_first(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data frames\n",
    "\n",
    "df1 = pd.DataFrame(data= [[np.nan, 45],[35, np.nan], [np.nan, 456]], index=['a', 'b', 'c'], columns=[\"ONE\", \"TWO\"])\n",
    "df2 = pd.DataFrame(data= [[5, 90],[np.nan, 0], [6, 6]], index=['a', 'b', 'c'], columns=[\"ONE\", \"TWO\"])\n",
    "df3 = pd.DataFrame(data= [[103, 24],[16, np.nan]], index=['a', 'c'], columns=[\"ONE\", \"TWO\"])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch df1 with df2\n",
    "\n",
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch df1 with df3: only 'a' and 'c' indexes are the same\n",
    "\n",
    "df1.combine_first(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Reshaping and Pivoting\n",
    "\n",
    "This is a mechanism to re-arrange data in a consistent manner. \n",
    "\n",
    "- **stack**: used to pivot from columns in the data  to rows\n",
    "\n",
    "- **unstack**: used to pivot from rows in the data  to columns\n",
    "\n",
    "> Note using **stack** will filter out missing data unless the **dropna** parameter is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=np.arange(6).reshape((2, 3)),\n",
    "                    index=pd.Index(['FOO', \"BAR\"], name='state'),\n",
    "                    columns=pd.Index(['one', 'two', 'three'], name='labels'))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change row data to columns\n",
    "\n",
    "res = data.unstack()\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default, if there are multi-index then unstacking will affect the inner index \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the state index to column\n",
    "res2 = res.unstack()\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index to use: if the index name is not specidied, then integer indexing\n",
    "# will be specified; smaller(outer) -> larger(inner): from 0, 1...\n",
    "\n",
    "res3 = res.unstack(level='labels')\n",
    "# equivalent to ;\n",
    "# res3 = res.unstack(level=0)\n",
    "\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing columns to rows\n",
    "\n",
    "res = data.stack()\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the indexes\n",
    "\n",
    "res.swaplevel('labels', 'state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking filters out missing data by default; specifying the dropna to False prevent this from happening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame(data=np.array([23, np.nan, 15, 56, np.nan, 34]).reshape(3, 2),\n",
    "                 index=pd.Index(['one', 'two', 'three'], name='rows'),\n",
    "                 columns=pd.Index(['FOO', 'BAR'], name='columns')\n",
    ")\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns to rows\n",
    "\n",
    "res1 = s.stack()\n",
    "\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed above that the null data has been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not filter out missing data using the dropna keyword\n",
    "\n",
    "s.stack(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change rows to column\n",
    "\n",
    "res2 = s.unstack()\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstack doesn't filter out missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>realgdp</th>\n",
       "      <th>realcons</th>\n",
       "      <th>realinv</th>\n",
       "      <th>realgovt</th>\n",
       "      <th>realdpi</th>\n",
       "      <th>cpi</th>\n",
       "      <th>m1</th>\n",
       "      <th>tbilrate</th>\n",
       "      <th>unemp</th>\n",
       "      <th>pop</th>\n",
       "      <th>infl</th>\n",
       "      <th>realint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>2710.349</td>\n",
       "      <td>1707.4</td>\n",
       "      <td>286.898</td>\n",
       "      <td>470.045</td>\n",
       "      <td>1886.9</td>\n",
       "      <td>28.98</td>\n",
       "      <td>139.7</td>\n",
       "      <td>2.82</td>\n",
       "      <td>5.8</td>\n",
       "      <td>177.146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959</td>\n",
       "      <td>2</td>\n",
       "      <td>2778.801</td>\n",
       "      <td>1733.7</td>\n",
       "      <td>310.859</td>\n",
       "      <td>481.301</td>\n",
       "      <td>1919.7</td>\n",
       "      <td>29.15</td>\n",
       "      <td>141.7</td>\n",
       "      <td>3.08</td>\n",
       "      <td>5.1</td>\n",
       "      <td>177.830</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959</td>\n",
       "      <td>3</td>\n",
       "      <td>2775.488</td>\n",
       "      <td>1751.8</td>\n",
       "      <td>289.226</td>\n",
       "      <td>491.260</td>\n",
       "      <td>1916.4</td>\n",
       "      <td>29.35</td>\n",
       "      <td>140.5</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.3</td>\n",
       "      <td>178.657</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959</td>\n",
       "      <td>4</td>\n",
       "      <td>2785.204</td>\n",
       "      <td>1753.7</td>\n",
       "      <td>299.356</td>\n",
       "      <td>484.052</td>\n",
       "      <td>1931.3</td>\n",
       "      <td>29.37</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.6</td>\n",
       "      <td>179.386</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "      <td>2847.699</td>\n",
       "      <td>1770.5</td>\n",
       "      <td>331.722</td>\n",
       "      <td>462.199</td>\n",
       "      <td>1955.5</td>\n",
       "      <td>29.54</td>\n",
       "      <td>139.6</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>180.007</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1960</td>\n",
       "      <td>2</td>\n",
       "      <td>2834.390</td>\n",
       "      <td>1792.9</td>\n",
       "      <td>298.152</td>\n",
       "      <td>460.400</td>\n",
       "      <td>1966.1</td>\n",
       "      <td>29.55</td>\n",
       "      <td>140.2</td>\n",
       "      <td>2.68</td>\n",
       "      <td>5.2</td>\n",
       "      <td>180.671</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1960</td>\n",
       "      <td>3</td>\n",
       "      <td>2839.022</td>\n",
       "      <td>1785.8</td>\n",
       "      <td>296.375</td>\n",
       "      <td>474.676</td>\n",
       "      <td>1967.8</td>\n",
       "      <td>29.75</td>\n",
       "      <td>140.9</td>\n",
       "      <td>2.36</td>\n",
       "      <td>5.6</td>\n",
       "      <td>181.528</td>\n",
       "      <td>2.70</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1960</td>\n",
       "      <td>4</td>\n",
       "      <td>2802.616</td>\n",
       "      <td>1788.2</td>\n",
       "      <td>259.764</td>\n",
       "      <td>476.434</td>\n",
       "      <td>1966.6</td>\n",
       "      <td>29.84</td>\n",
       "      <td>141.1</td>\n",
       "      <td>2.29</td>\n",
       "      <td>6.3</td>\n",
       "      <td>182.287</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>2819.264</td>\n",
       "      <td>1787.7</td>\n",
       "      <td>266.405</td>\n",
       "      <td>475.854</td>\n",
       "      <td>1984.5</td>\n",
       "      <td>29.81</td>\n",
       "      <td>142.1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>6.8</td>\n",
       "      <td>182.992</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1961</td>\n",
       "      <td>2</td>\n",
       "      <td>2872.005</td>\n",
       "      <td>1814.3</td>\n",
       "      <td>286.246</td>\n",
       "      <td>480.328</td>\n",
       "      <td>2014.4</td>\n",
       "      <td>29.92</td>\n",
       "      <td>142.9</td>\n",
       "      <td>2.29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>183.691</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi  \\\n",
       "0  1959        1  2710.349    1707.4  286.898   470.045   1886.9  28.98   \n",
       "1  1959        2  2778.801    1733.7  310.859   481.301   1919.7  29.15   \n",
       "2  1959        3  2775.488    1751.8  289.226   491.260   1916.4  29.35   \n",
       "3  1959        4  2785.204    1753.7  299.356   484.052   1931.3  29.37   \n",
       "4  1960        1  2847.699    1770.5  331.722   462.199   1955.5  29.54   \n",
       "5  1960        2  2834.390    1792.9  298.152   460.400   1966.1  29.55   \n",
       "6  1960        3  2839.022    1785.8  296.375   474.676   1967.8  29.75   \n",
       "7  1960        4  2802.616    1788.2  259.764   476.434   1966.6  29.84   \n",
       "8  1961        1  2819.264    1787.7  266.405   475.854   1984.5  29.81   \n",
       "9  1961        2  2872.005    1814.3  286.246   480.328   2014.4  29.92   \n",
       "\n",
       "      m1  tbilrate  unemp      pop  infl  realint  \n",
       "0  139.7      2.82    5.8  177.146  0.00     0.00  \n",
       "1  141.7      3.08    5.1  177.830  2.34     0.74  \n",
       "2  140.5      3.82    5.3  178.657  2.74     1.09  \n",
       "3  140.0      4.33    5.6  179.386  0.27     4.06  \n",
       "4  139.6      3.50    5.2  180.007  2.31     1.19  \n",
       "5  140.2      2.68    5.2  180.671  0.14     2.55  \n",
       "6  140.9      2.36    5.6  181.528  2.70    -0.34  \n",
       "7  141.1      2.29    6.3  182.287  1.21     1.08  \n",
       "8  142.1      2.37    6.8  182.992 -0.40     2.77  \n",
       "9  142.9      2.29    7.0  183.691  1.47     0.81  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"../datasets/examples/macrodata.csv\"\n",
    "\n",
    "data = pd.read_csv(file_name)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')\n",
    "\n",
    "columns = pd.Index(['realgdp', 'infl', 'unemp'], name='item')\n",
    "\n",
    "data_mod = data.reindex(columns=columns)\n",
    "\n",
    "data_mod.index= periods.to_timestamp('D', 'end')\n",
    "\n",
    "ldata= data_mod.stack().reset_index().rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959-03-31 23:59:59.999999999</td>\n",
       "      <td>realgdp</td>\n",
       "      <td>2710.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959-03-31 23:59:59.999999999</td>\n",
       "      <td>infl</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959-03-31 23:59:59.999999999</td>\n",
       "      <td>unemp</td>\n",
       "      <td>5.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-06-30 23:59:59.999999999</td>\n",
       "      <td>realgdp</td>\n",
       "      <td>2778.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959-06-30 23:59:59.999999999</td>\n",
       "      <td>infl</td>\n",
       "      <td>2.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date     item     value\n",
       "0 1959-03-31 23:59:59.999999999  realgdp  2710.349\n",
       "1 1959-03-31 23:59:59.999999999     infl     0.000\n",
       "2 1959-03-31 23:59:59.999999999    unemp     5.800\n",
       "3 1959-06-30 23:59:59.999999999  realgdp  2778.801\n",
       "4 1959-06-30 23:59:59.999999999     infl     2.340"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Pivotting Dataframe\n",
    "\n",
    "This is a mechanism where a given column data is turned (pivotted) as column labels; turning the data from a **long rows to wide columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>infl</th>\n",
       "      <th>realgdp</th>\n",
       "      <th>unemp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-03-31 23:59:59.999999999</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2710.349</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-06-30 23:59:59.999999999</th>\n",
       "      <td>2.34</td>\n",
       "      <td>2778.801</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-09-30 23:59:59.999999999</th>\n",
       "      <td>2.74</td>\n",
       "      <td>2775.488</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-12-31 23:59:59.999999999</th>\n",
       "      <td>0.27</td>\n",
       "      <td>2785.204</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-03-31 23:59:59.999999999</th>\n",
       "      <td>2.31</td>\n",
       "      <td>2847.699</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-30 23:59:59.999999999</th>\n",
       "      <td>-3.16</td>\n",
       "      <td>13324.600</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31 23:59:59.999999999</th>\n",
       "      <td>-8.79</td>\n",
       "      <td>13141.920</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-31 23:59:59.999999999</th>\n",
       "      <td>0.94</td>\n",
       "      <td>12925.410</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-30 23:59:59.999999999</th>\n",
       "      <td>3.37</td>\n",
       "      <td>12901.504</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-30 23:59:59.999999999</th>\n",
       "      <td>3.56</td>\n",
       "      <td>12990.341</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item                           infl    realgdp  unemp\n",
       "date                                                 \n",
       "1959-03-31 23:59:59.999999999  0.00   2710.349    5.8\n",
       "1959-06-30 23:59:59.999999999  2.34   2778.801    5.1\n",
       "1959-09-30 23:59:59.999999999  2.74   2775.488    5.3\n",
       "1959-12-31 23:59:59.999999999  0.27   2785.204    5.6\n",
       "1960-03-31 23:59:59.999999999  2.31   2847.699    5.2\n",
       "...                             ...        ...    ...\n",
       "2008-09-30 23:59:59.999999999 -3.16  13324.600    6.0\n",
       "2008-12-31 23:59:59.999999999 -8.79  13141.920    6.9\n",
       "2009-03-31 23:59:59.999999999  0.94  12925.410    8.1\n",
       "2009-06-30 23:59:59.999999999  3.37  12901.504    9.2\n",
       "2009-09-30 23:59:59.999999999  3.56  12990.341    9.6\n",
       "\n",
       "[203 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the index as the data column, and the columns as the categorical data in the 'item' column\n",
    "pivoted = ldata.pivot(index='date', columns='item', values='value')\n",
    "\n",
    "pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalence between **pivot**, and [].set_index([.]).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ldata.set_index(['date', 'item']).unstack('item')\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Melting Data\n",
    "\n",
    "This performs the inverse of **pivot**, by turning a set of columns to row data; turning a wide column data to long row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(p, ignore_index=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "## Chapter 9: Data Aggregation & Grouping\n",
    "\n",
    "- split objects into pieces\n",
    "\n",
    "- compute group statistics\n",
    "\n",
    "- apply group transformation\n",
    "\n",
    "- compute pivot tables and cross-tabulations\n",
    "\n",
    "- perform statiscal group analyses\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "#### GroupBy Mechanics\n",
    "\n",
    "This is a mechanism for grouping data based on one or more keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "  'key1': ['a', 'a', 'b', 'b', 'a'],\n",
    "  'key2': ['one', 'two', 'one', 'two', 'one'],\n",
    "  'data1': np.random.randn(5),\n",
    "  'data2': np.random.randn(5)\n",
    "  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean of data1 using key1 as the label or the mean of data1 with a, b as keys\n",
    "\n",
    "grouped = df['data1'].groupby(df['key1'])\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the key1, and key2 to group the data1, and then compute the mean\n",
    "\n",
    "means = df['data1'].groupby(by=[df['key1'], df['key2']]).mean()\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above grouping mechanics, it is assumed as though the group keys -> ***key1, key2***, does not belong to the data from the way the statement is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack the data\n",
    "\n",
    "means.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an array not belonging to the data to be grouped for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Lagos', 'Abuja', 'Abuja', 'Lagos', 'Lagos']\n",
    "\n",
    "years = [2010, 2009, 2009, 2009, 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data1'].groupby([states, years]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the group keys belong to the data, we can apply groupby directly\n",
    "\n",
    "df.groupby('key1').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using key1 and key2 to group\n",
    "\n",
    "g = df.groupby(['key1', 'key2'])\n",
    "\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sizes of each grouped data\n",
    "\n",
    "g.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default, missing data will be omitted from the result when using groupby method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(data={\n",
    "  'key1': ['b', 'a', 'a', 'b'],\n",
    "  'key2': ['one', 'two', 'one', 'one'],\n",
    "  'data1': [np.nan, 156, 23, 54],\n",
    "  'data2': [30, np.nan, 57, np.nan]\n",
    "})\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.groupby(by=['key1', 'key2']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that missing values are not accounted for in the meta-data of the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by key1, and observed missing values\n",
    "\n",
    "frame.groupby(by='key1').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that both values of 'a' are used in 'data1' column but a single value of 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---|||\n",
    "### Iterating Over Groups\n",
    "\n",
    "Groupby Object supports iteration, over its result. It returns a tuple of keys-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby('key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "\n",
      "  key1 key2     data1     data2\n",
      "0    a  one -0.199207  2.098223\n",
      "1    a  two  1.506196  1.391447\n",
      "4    a  one  2.149205  0.269702\n",
      "b\n",
      "\n",
      "  key1 key2     data1     data2\n",
      "2    b  one  1.588769 -1.387905\n",
      "3    b  two  1.492748 -0.052380\n"
     ]
    }
   ],
   "source": [
    "for name, group in grp:\n",
    "  print(name)\n",
    "  print()\n",
    "  print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2     data1     data2\n",
      "0    a  one -0.199207  2.098223\n",
      "1    a  two  1.506196  1.391447\n",
      "4    a  one  2.149205  0.269702\n",
      "  key1 key2     data1     data2\n",
      "2    b  one  1.588769 -1.387905\n",
      "3    b  two  1.492748 -0.052380\n"
     ]
    }
   ],
   "source": [
    "for k in grp:\n",
    "  print(k[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over multiple-keys grouping\n",
    "\n",
    "grp = df.groupby(by=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a one\n",
      "  key1 key2     data1     data2\n",
      "0    a  one -0.199207  2.098223\n",
      "4    a  one  2.149205  0.269702\n",
      "\n",
      "a two\n",
      "  key1 key2     data1     data2\n",
      "1    a  two  1.506196  1.391447\n",
      "\n",
      "b one\n",
      "  key1 key2     data1     data2\n",
      "2    b  one  1.588769 -1.387905\n",
      "\n",
      "b two\n",
      "  key1 key2     data1    data2\n",
      "3    b  two  1.492748 -0.05238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since there are two keys, we get a 3-tuple\n",
    "\n",
    "for (k1, k2), group in grp:\n",
    "  print(k1, k2)\n",
    "  print(group, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>one</td>\n",
       "      <td>1.588769</td>\n",
       "      <td>-1.387905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key1 key2     data1     data2\n",
       "2    b  one  1.588769 -1.387905"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(grp))['b', 'one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1      object\n",
       "key2      object\n",
       "data1    float64\n",
       "data2    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default groupby axis is 0 (index). This can be modified by setting the axis optional keyword parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby(df.dtypes, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "      data1     data2\n",
      "0 -0.199207  2.098223\n",
      "1  1.506196  1.391447\n",
      "2  1.588769 -1.387905\n",
      "3  1.492748 -0.052380\n",
      "4  2.149205  0.269702\n",
      "object\n",
      "  key1 key2\n",
      "0    a  one\n",
      "1    a  two\n",
      "2    b  one\n",
      "3    b  two\n",
      "4    a  one\n"
     ]
    }
   ],
   "source": [
    "for dtype, group in grp:\n",
    "  print(dtype)\n",
    "  print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Columns or Subset of Columns of Grouped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.199207</td>\n",
       "      <td>2.098223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>two</td>\n",
       "      <td>1.506196</td>\n",
       "      <td>1.391447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>one</td>\n",
       "      <td>1.588769</td>\n",
       "      <td>-1.387905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>two</td>\n",
       "      <td>1.492748</td>\n",
       "      <td>-0.052380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "      <td>2.149205</td>\n",
       "      <td>0.269702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key1 key2     data1     data2\n",
       "0    a  one -0.199207  2.098223\n",
       "1    a  two  1.506196  1.391447\n",
       "2    b  one  1.588769 -1.387905\n",
       "3    b  two  1.492748 -0.052380\n",
       "4    a  one  2.149205  0.269702"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7e69bb4d2e30>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by key1 and select the data1 column\n",
    "\n",
    "# df['data1'].groupby(by=df['key1']) # is equivalent to:\n",
    "\n",
    "df.groupby('key1')['data1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping with Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COLUMNS</th>\n",
       "      <th>ONE</th>\n",
       "      <th>TWO</th>\n",
       "      <th>THREE</th>\n",
       "      <th>FOUR</th>\n",
       "      <th>FIVE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROWS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.253309</td>\n",
       "      <td>-1.086819</td>\n",
       "      <td>-0.838136</td>\n",
       "      <td>-0.120427</td>\n",
       "      <td>0.694268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-0.163638</td>\n",
       "      <td>-1.376051</td>\n",
       "      <td>-0.790970</td>\n",
       "      <td>-0.115774</td>\n",
       "      <td>0.360131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.026162</td>\n",
       "      <td>0.668005</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>-0.024915</td>\n",
       "      <td>-0.415114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>-0.416121</td>\n",
       "      <td>-0.053862</td>\n",
       "      <td>0.870667</td>\n",
       "      <td>1.788469</td>\n",
       "      <td>-1.427654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.395446</td>\n",
       "      <td>-0.271426</td>\n",
       "      <td>-0.274036</td>\n",
       "      <td>-0.359843</td>\n",
       "      <td>-1.119527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COLUMNS       ONE       TWO     THREE      FOUR      FIVE\n",
       "ROWS                                                     \n",
       "a       -0.253309 -1.086819 -0.838136 -0.120427  0.694268\n",
       "b       -0.163638 -1.376051 -0.790970 -0.115774  0.360131\n",
       "c        0.026162  0.668005  0.014478 -0.024915 -0.415114\n",
       "d       -0.416121 -0.053862  0.870667  1.788469 -1.427654\n",
       "e        0.395446 -0.271426 -0.274036 -0.359843 -1.119527"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "  data=np.random.randn(5, 5),\n",
    "  columns=pd.Index(['ONE', 'TWO', 'THREE', 'FOUR', 'FIVE'], name='COLUMNS'),\n",
    "  index=pd.Index(['a', 'b', 'c', 'd', 'e'], name='ROWS')\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_1 = {'ONE': 'MO', 'TWO': 'WOLE', 'THREE':'WOLE', 'FOUR': 'MO', 'FIVE': 'MO'}\n",
    "mapping_2 = {'a': 'MO', 'c': 'WOLE', 'e':'WOLE', 'b': 'MO', 'f': 'MO'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observe the key 'f' assigned to 'MO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_col = df.groupby(mapping_1, axis=1)\n",
    "grp_row = df.groupby(mapping_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COLUMNS\n",
       "MO      3\n",
       "WOLE    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_col.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROWS\n",
       "MO      2\n",
       "WOLE    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_row.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the key 'f', above, is ignored since it is not in grouping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COLUMNS</th>\n",
       "      <th>MO</th>\n",
       "      <th>WOLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROWS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.320532</td>\n",
       "      <td>-1.924954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.080719</td>\n",
       "      <td>-2.167021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-0.413867</td>\n",
       "      <td>0.682483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>-0.055305</td>\n",
       "      <td>0.816805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>-1.083924</td>\n",
       "      <td>-0.545462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COLUMNS        MO      WOLE\n",
       "ROWS                       \n",
       "a        0.320532 -1.924954\n",
       "b        0.080719 -2.167021\n",
       "c       -0.413867  0.682483\n",
       "d       -0.055305  0.816805\n",
       "e       -1.083924 -0.545462"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_col.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COLUMNS</th>\n",
       "      <th>ONE</th>\n",
       "      <th>TWO</th>\n",
       "      <th>THREE</th>\n",
       "      <th>FOUR</th>\n",
       "      <th>FIVE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROWS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>-0.416947</td>\n",
       "      <td>-2.462870</td>\n",
       "      <td>-1.629105</td>\n",
       "      <td>-0.236201</td>\n",
       "      <td>1.054399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WOLE</th>\n",
       "      <td>0.421608</td>\n",
       "      <td>0.396579</td>\n",
       "      <td>-0.259558</td>\n",
       "      <td>-0.384758</td>\n",
       "      <td>-1.534641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COLUMNS       ONE       TWO     THREE      FOUR      FIVE\n",
       "ROWS                                                     \n",
       "MO      -0.416947 -2.462870 -1.629105 -0.236201  1.054399\n",
       "WOLE     0.421608  0.396579 -0.259558 -0.384758 -1.534641"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_row.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "#### Grouping with Function\n",
    "\n",
    "The function is applied to the index if axis=0 and colum if axis=1, as though they were keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COLUMNS</th>\n",
       "      <th>ONE</th>\n",
       "      <th>TWO</th>\n",
       "      <th>THREE</th>\n",
       "      <th>FOUR</th>\n",
       "      <th>FIVE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROWS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.253309</td>\n",
       "      <td>-1.086819</td>\n",
       "      <td>-0.838136</td>\n",
       "      <td>-0.120427</td>\n",
       "      <td>0.694268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-0.163638</td>\n",
       "      <td>-1.376051</td>\n",
       "      <td>-0.790970</td>\n",
       "      <td>-0.115774</td>\n",
       "      <td>0.360131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.026162</td>\n",
       "      <td>0.668005</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>-0.024915</td>\n",
       "      <td>-0.415114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>-0.416121</td>\n",
       "      <td>-0.053862</td>\n",
       "      <td>0.870667</td>\n",
       "      <td>1.788469</td>\n",
       "      <td>-1.427654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.395446</td>\n",
       "      <td>-0.271426</td>\n",
       "      <td>-0.274036</td>\n",
       "      <td>-0.359843</td>\n",
       "      <td>-1.119527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COLUMNS       ONE       TWO     THREE      FOUR      FIVE\n",
       "ROWS                                                     \n",
       "a       -0.253309 -1.086819 -0.838136 -0.120427  0.694268\n",
       "b       -0.163638 -1.376051 -0.790970 -0.115774  0.360131\n",
       "c        0.026162  0.668005  0.014478 -0.024915 -0.415114\n",
       "d       -0.416121 -0.053862  0.870667  1.788469 -1.427654\n",
       "e        0.395446 -0.271426 -0.274036 -0.359843 -1.119527"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COLUMNS</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROWS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COLUMNS  3  4  5\n",
       "ROWS            \n",
       "a        2  2  1\n",
       "b        2  2  1\n",
       "c        2  2  1\n",
       "d        2  2  1\n",
       "e        2  2  1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(len, axis=1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to mix function and arrays, dict or series as grouping mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROWS</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLUMNS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ONE</th>\n",
       "      <td>-0.253309</td>\n",
       "      <td>-0.163638</td>\n",
       "      <td>0.026162</td>\n",
       "      <td>-0.416121</td>\n",
       "      <td>0.395446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TWO</th>\n",
       "      <td>-1.086819</td>\n",
       "      <td>-1.376051</td>\n",
       "      <td>0.668005</td>\n",
       "      <td>-0.053862</td>\n",
       "      <td>-0.271426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THREE</th>\n",
       "      <td>-0.838136</td>\n",
       "      <td>-0.790970</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>0.870667</td>\n",
       "      <td>-0.274036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOUR</th>\n",
       "      <td>-0.120427</td>\n",
       "      <td>-0.115774</td>\n",
       "      <td>-0.024915</td>\n",
       "      <td>1.788469</td>\n",
       "      <td>-0.359843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIVE</th>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.360131</td>\n",
       "      <td>-0.415114</td>\n",
       "      <td>-1.427654</td>\n",
       "      <td>-1.119527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROWS            a         b         c         d         e\n",
       "COLUMNS                                                  \n",
       "ONE     -0.253309 -0.163638  0.026162 -0.416121  0.395446\n",
       "TWO     -1.086819 -1.376051  0.668005 -0.053862 -0.271426\n",
       "THREE   -0.838136 -0.790970  0.014478  0.870667 -0.274036\n",
       "FOUR    -0.120427 -0.115774 -0.024915  1.788469 -0.359843\n",
       "FIVE     0.694268  0.360131 -0.415114 -1.427654 -1.119527"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.unstack().unstack()\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COLUMNS  a          b        \n",
       "3        -1.086819  -1.376051    1\n",
       "         -0.253309  -0.163638    1\n",
       "4        -0.120427  -0.115774    1\n",
       "          0.694268   0.360131    1\n",
       "5        -0.838136  -0.790970    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(by=[len, 'a', 'b']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Data Aggregation\n",
    "\n",
    "This is a mechanism of producing a scalar value (a single value) from a arrays. This is achieved by passing the aggregating mechanism to **agg** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>key1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.128287</td>\n",
       "      <td>ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.260543</td>\n",
       "      <td>TWO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750654</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.586161</td>\n",
       "      <td>0.618188</td>\n",
       "      <td>TWO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348354</td>\n",
       "      <td>0.113318</td>\n",
       "      <td>TWO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data1     data2 key1\n",
       "0  0.783589  0.128287  ONE\n",
       "1  0.017067  0.260543  TWO\n",
       "2  0.750654  0.796380  ONE\n",
       "3  0.586161  0.618188  TWO\n",
       "4  0.348354  0.113318  TWO"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "  data={\n",
    "    'data1': np.random.random(5),\n",
    "    'data2': np.random.random(5),\n",
    "    'key1': ['a', 'b', 'a', 'a', 'b'],\n",
    "    'key1': ['ONE', 'TWO', 'ONE','TWO', 'TWO']\n",
    "  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data1 by grouping using 'key1' \n",
    "\n",
    "grp = df.groupby(by='key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1\n",
       "ONE    1.534244\n",
       "TWO    0.951582\n",
       "Name: data1, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate by sums\n",
    "\n",
    "grp['data1'].agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1\n",
       "ONE    0.462333\n",
       "TWO    0.330683\n",
       "Name: data2, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean aggregation\n",
    "def means(arr):\n",
    "  return np.mean(arr)\n",
    "\n",
    "grp['data2'].aggregate(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"../datasets/examples/tips.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip smoker  day    time  size\n",
       "0       16.99  1.01     No  Sun  Dinner     2\n",
       "1       10.34  1.66     No  Sun  Dinner     3\n",
       "2       21.01  3.50     No  Sun  Dinner     3\n",
       "3       23.68  3.31     No  Sun  Dinner     2\n",
       "4       24.59  3.61     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = pd.read_csv(fn)\n",
    "\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.160542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.146808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip smoker  day    time  size   tip_pct\n",
       "0       16.99  1.01     No  Sun  Dinner     2  0.059447\n",
       "1       10.34  1.66     No  Sun  Dinner     3  0.160542\n",
       "2       21.01  3.50     No  Sun  Dinner     3  0.166587\n",
       "3       23.68  3.31     No  Sun  Dinner     2  0.139780\n",
       "4       24.59  3.61     No  Sun  Dinner     4  0.146808"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips['tip_pct'] = tips['tip'] / tips['total_bill']\n",
    "\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">total_bill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_bill                     \n",
       "day        Fri    Sat    Sun   Thur\n",
       "0          NaN    NaN  16.99    NaN\n",
       "1          NaN    NaN  10.34    NaN\n",
       "2          NaN    NaN  21.01    NaN\n",
       "3          NaN    NaN  23.68    NaN\n",
       "4          NaN    NaN  24.59    NaN\n",
       "..         ...    ...    ...    ...\n",
       "239        NaN  29.03    NaN    NaN\n",
       "240        NaN  27.18    NaN    NaN\n",
       "241        NaN  22.67    NaN    NaN\n",
       "242        NaN  17.82    NaN    NaN\n",
       "243        NaN    NaN    NaN  18.78\n",
       "\n",
       "[244 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying the pivot func\n",
    "\n",
    "tips.pivot( columns='day', values=['total_bill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by day and smoker\n",
    "\n",
    "grp = tips.groupby([ 'day', 'smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day   smoker\n",
       "Fri   No        0.151650\n",
       "      Yes       0.174783\n",
       "Sat   No        0.158048\n",
       "      Yes       0.147906\n",
       "Sun   No        0.160113\n",
       "      Yes       0.187250\n",
       "Thur  No        0.160298\n",
       "      Yes       0.163863\n",
       "Name: tip_pct, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the mean of the tip_pct based on day and smoke preference\n",
    "\n",
    "grp['tip_pct'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Average</th>\n",
       "      <th>Standard-Deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fri</th>\n",
       "      <th>No</th>\n",
       "      <td>0.151650</td>\n",
       "      <td>0.028123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>0.051293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>No</th>\n",
       "      <td>0.158048</td>\n",
       "      <td>0.039767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.147906</td>\n",
       "      <td>0.061375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sun</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160113</td>\n",
       "      <td>0.042347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.187250</td>\n",
       "      <td>0.154134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thur</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160298</td>\n",
       "      <td>0.038774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.163863</td>\n",
       "      <td>0.039389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average  Standard-Deviation\n",
       "day  smoker                              \n",
       "Fri  No      0.151650            0.028123\n",
       "     Yes     0.174783            0.051293\n",
       "Sat  No      0.158048            0.039767\n",
       "     Yes     0.147906            0.061375\n",
       "Sun  No      0.160113            0.042347\n",
       "     Yes     0.187250            0.154134\n",
       "Thur No      0.160298            0.038774\n",
       "     Yes     0.163863            0.039389"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple aggregating function\n",
    "\n",
    "grp_pct = grp['tip_pct']\n",
    "\n",
    "grp_pct.agg([('Average', 'mean'), ('Standard-Deviation', 'std')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">tip_pct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">total_bill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>MAX</th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>MAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fri</th>\n",
       "      <th>No</th>\n",
       "      <td>0.151650</td>\n",
       "      <td>0.187735</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>0.263480</td>\n",
       "      <td>16.813333</td>\n",
       "      <td>40.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>No</th>\n",
       "      <td>0.158048</td>\n",
       "      <td>0.291990</td>\n",
       "      <td>19.661778</td>\n",
       "      <td>48.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.147906</td>\n",
       "      <td>0.325733</td>\n",
       "      <td>21.276667</td>\n",
       "      <td>50.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sun</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160113</td>\n",
       "      <td>0.252672</td>\n",
       "      <td>20.506667</td>\n",
       "      <td>48.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.187250</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>24.120000</td>\n",
       "      <td>45.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thur</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160298</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>17.113111</td>\n",
       "      <td>41.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.163863</td>\n",
       "      <td>0.241255</td>\n",
       "      <td>19.190588</td>\n",
       "      <td>43.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tip_pct           total_bill       \n",
       "              AVERAGE       MAX    AVERAGE    MAX\n",
       "day  smoker                                      \n",
       "Fri  No      0.151650  0.187735  18.420000  22.75\n",
       "     Yes     0.174783  0.263480  16.813333  40.17\n",
       "Sat  No      0.158048  0.291990  19.661778  48.33\n",
       "     Yes     0.147906  0.325733  21.276667  50.81\n",
       "Sun  No      0.160113  0.252672  20.506667  48.17\n",
       "     Yes     0.187250  0.710345  24.120000  45.35\n",
       "Thur No      0.160298  0.266312  17.113111  41.19\n",
       "     Yes     0.163863  0.241255  19.190588  43.11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_agg = grp[['tip_pct', 'total_bill']].agg([('AVERAGE', 'mean'), ('MAX', max)])\n",
    "\n",
    "multi_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>MAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fri</th>\n",
       "      <th>No</th>\n",
       "      <td>0.151650</td>\n",
       "      <td>0.187735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>0.263480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>No</th>\n",
       "      <td>0.158048</td>\n",
       "      <td>0.291990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.147906</td>\n",
       "      <td>0.325733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sun</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160113</td>\n",
       "      <td>0.252672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.187250</td>\n",
       "      <td>0.710345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thur</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160298</td>\n",
       "      <td>0.266312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.163863</td>\n",
       "      <td>0.241255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AVERAGE       MAX\n",
       "day  smoker                    \n",
       "Fri  No      0.151650  0.187735\n",
       "     Yes     0.174783  0.263480\n",
       "Sat  No      0.158048  0.291990\n",
       "     Yes     0.147906  0.325733\n",
       "Sun  No      0.160113  0.252672\n",
       "     Yes     0.187250  0.710345\n",
       "Thur No      0.160298  0.266312\n",
       "     Yes     0.163863  0.241255"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = multi_agg['tip_pct']\n",
    "s = multi_agg['total_bill']\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>MAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fri</th>\n",
       "      <th>No</th>\n",
       "      <td>18.420000</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>16.813333</td>\n",
       "      <td>40.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>No</th>\n",
       "      <td>19.661778</td>\n",
       "      <td>48.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>21.276667</td>\n",
       "      <td>50.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sun</th>\n",
       "      <th>No</th>\n",
       "      <td>20.506667</td>\n",
       "      <td>48.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>24.120000</td>\n",
       "      <td>45.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thur</th>\n",
       "      <th>No</th>\n",
       "      <td>17.113111</td>\n",
       "      <td>41.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>19.190588</td>\n",
       "      <td>43.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AVERAGE    MAX\n",
       "day  smoker                  \n",
       "Fri  No      18.420000  22.75\n",
       "     Yes     16.813333  40.17\n",
       "Sat  No      19.661778  48.33\n",
       "     Yes     21.276667  50.81\n",
       "Sun  No      20.506667  48.17\n",
       "     Yes     24.120000  45.35\n",
       "Thur No      17.113111  41.19\n",
       "     Yes     19.190588  43.11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">tip_pct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">total_bill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>MAX</th>\n",
       "      <th>AVERAGE</th>\n",
       "      <th>MAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fri</th>\n",
       "      <th>No</th>\n",
       "      <td>0.151650</td>\n",
       "      <td>0.187735</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>0.263480</td>\n",
       "      <td>16.813333</td>\n",
       "      <td>40.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>No</th>\n",
       "      <td>0.158048</td>\n",
       "      <td>0.291990</td>\n",
       "      <td>19.661778</td>\n",
       "      <td>48.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.147906</td>\n",
       "      <td>0.325733</td>\n",
       "      <td>21.276667</td>\n",
       "      <td>50.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sun</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160113</td>\n",
       "      <td>0.252672</td>\n",
       "      <td>20.506667</td>\n",
       "      <td>48.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.187250</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>24.120000</td>\n",
       "      <td>45.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thur</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160298</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>17.113111</td>\n",
       "      <td>41.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.163863</td>\n",
       "      <td>0.241255</td>\n",
       "      <td>19.190588</td>\n",
       "      <td>43.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tip_pct           total_bill       \n",
       "              AVERAGE       MAX    AVERAGE    MAX\n",
       "day  smoker                                      \n",
       "Fri  No      0.151650  0.187735  18.420000  22.75\n",
       "     Yes     0.174783  0.263480  16.813333  40.17\n",
       "Sat  No      0.158048  0.291990  19.661778  48.33\n",
       "     Yes     0.147906  0.325733  21.276667  50.81\n",
       "Sun  No      0.160113  0.252672  20.506667  48.17\n",
       "     Yes     0.187250  0.710345  24.120000  45.35\n",
       "Thur No      0.160298  0.266312  17.113111  41.19\n",
       "     Yes     0.163863  0.241255  19.190588  43.11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat({'tip_pct': t, 'total_bill': s}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tip_pct</th>\n",
       "      <th>total_bill</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fri</th>\n",
       "      <th>No</th>\n",
       "      <td>0.151650</td>\n",
       "      <td>5.059282</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>9.086388</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>No</th>\n",
       "      <td>0.158048</td>\n",
       "      <td>8.939181</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.147906</td>\n",
       "      <td>10.069138</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sun</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160113</td>\n",
       "      <td>8.130189</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.187250</td>\n",
       "      <td>10.442511</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thur</th>\n",
       "      <th>No</th>\n",
       "      <td>0.160298</td>\n",
       "      <td>7.721728</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.163863</td>\n",
       "      <td>8.355149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tip_pct  total_bill  size\n",
       "day  smoker                            \n",
       "Fri  No      0.151650    5.059282     3\n",
       "     Yes     0.174783    9.086388     4\n",
       "Sat  No      0.158048    8.939181     4\n",
       "     Yes     0.147906   10.069138     5\n",
       "Sun  No      0.160113    8.130189     6\n",
       "     Yes     0.187250   10.442511     5\n",
       "Thur No      0.160298    7.721728     6\n",
       "     Yes     0.163863    8.355149     4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply different aggregating functions to different columns\n",
    "\n",
    "res = grp.agg({'tip_pct': np.mean, 'total_bill': 'std', 'size': np.max})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th>tip_pct</th>\n",
       "      <th>total_bill</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri</td>\n",
       "      <td>No</td>\n",
       "      <td>0.151650</td>\n",
       "      <td>5.059282</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.174783</td>\n",
       "      <td>9.086388</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat</td>\n",
       "      <td>No</td>\n",
       "      <td>0.158048</td>\n",
       "      <td>8.939181</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.147906</td>\n",
       "      <td>10.069138</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun</td>\n",
       "      <td>No</td>\n",
       "      <td>0.160113</td>\n",
       "      <td>8.130189</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.187250</td>\n",
       "      <td>10.442511</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thur</td>\n",
       "      <td>No</td>\n",
       "      <td>0.160298</td>\n",
       "      <td>7.721728</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thur</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.163863</td>\n",
       "      <td>8.355149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    day smoker   tip_pct  total_bill  size\n",
       "0   Fri     No  0.151650    5.059282     3\n",
       "1   Fri    Yes  0.174783    9.086388     4\n",
       "2   Sat     No  0.158048    8.939181     4\n",
       "3   Sat    Yes  0.147906   10.069138     5\n",
       "4   Sun     No  0.160113    8.130189     6\n",
       "5   Sun    Yes  0.187250   10.442511     5\n",
       "6  Thur     No  0.160298    7.721728     6\n",
       "7  Thur    Yes  0.163863    8.355149     4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not want to ignore the index of the result, so we specify 'as_index'\n",
    "\n",
    "# multiple aggregating function\n",
    "\n",
    "res = tips.groupby(['day', 'smoker'], as_index=False).agg(\n",
    "  {'tip_pct': np.mean, 'total_bill': 'std', 'size': np.max})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>day</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thur</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.059282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.086388</td>\n",
       "      <td>8.939181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.355149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.069138</td>\n",
       "      <td>10.442511</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.130189</td>\n",
       "      <td>7.721728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "day        Fri        Sat        Sun      Thur\n",
       "size                                          \n",
       "3     5.059282        NaN        NaN       NaN\n",
       "4     9.086388   8.939181        NaN  8.355149\n",
       "5          NaN  10.069138  10.442511       NaN\n",
       "6          NaN        NaN   8.130189  7.721728"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.pivot(index='size', columns='day', values='total_bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>day</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable value\n",
       "0      day   Fri\n",
       "1      day   Fri\n",
       "2      day   Sat\n",
       "3      day   Sat\n",
       "4      day   Sun"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = pd.melt(res)\n",
    "\n",
    "res2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Split-Apply-Combine\n",
    "\n",
    "This is the mechanism used by **groupby** and applied **aggregating** function.. While the -\n",
    "\n",
    "1. **split** is performed by the **groupby** method\n",
    "2. **apply**, used on the result of the *groupby* method, is performed either by\n",
    "    - aggregating the function\n",
    "    - using the **apply** method on the group result\n",
    "3. **combine** is performed, automatically, after aggregating the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that selects the first 6 largest value by column\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "def top_n(df: DataFrame, n=5, column='tip_pct'):\n",
    "  return df.sort_values(by=column)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>7.51</td>\n",
       "      <td>2.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.266312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>14.31</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>23.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>11.61</td>\n",
       "      <td>3.39</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>9.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip smoker   day    time  size   tip_pct\n",
       "149        7.51  2.00     No  Thur   Lunch     2  0.266312\n",
       "109       14.31  4.00    Yes   Sat  Dinner     2  0.279525\n",
       "183       23.17  6.50    Yes   Sun  Dinner     4  0.280535\n",
       "232       11.61  3.39     No   Sat  Dinner     2  0.291990\n",
       "67         3.07  1.00    Yes   Sat  Dinner     1  0.325733\n",
       "178        9.60  4.00    Yes   Sun  Dinner     2  0.416667\n",
       "172        7.25  5.15    Yes   Sun  Dinner     2  0.710345"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n(tips, n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
       "      <th>88</th>\n",
       "      <td>24.71</td>\n",
       "      <td>5.85</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.236746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>20.69</td>\n",
       "      <td>5.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>5</td>\n",
       "      <td>0.241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10.29</td>\n",
       "      <td>2.60</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.252672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>7.51</td>\n",
       "      <td>2.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.266312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>11.61</td>\n",
       "      <td>3.39</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
       "      <th>109</th>\n",
       "      <td>14.31</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>23.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>9.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_bill   tip smoker   day    time  size   tip_pct\n",
       "smoker                                                           \n",
       "No     88        24.71  5.85     No  Thur   Lunch     2  0.236746\n",
       "       185       20.69  5.00     No   Sun  Dinner     5  0.241663\n",
       "       51        10.29  2.60     No   Sun  Dinner     2  0.252672\n",
       "       149        7.51  2.00     No  Thur   Lunch     2  0.266312\n",
       "       232       11.61  3.39     No   Sat  Dinner     2  0.291990\n",
       "Yes    109       14.31  4.00    Yes   Sat  Dinner     2  0.279525\n",
       "       183       23.17  6.50    Yes   Sun  Dinner     4  0.280535\n",
       "       67         3.07  1.00    Yes   Sat  Dinner     1  0.325733\n",
       "       178        9.60  4.00    Yes   Sun  Dinner     2  0.416667\n",
       "       172        7.25  5.15    Yes   Sun  Dinner     2  0.710345"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by smoker and apply the function\n",
    "\n",
    "tips.groupby(by='smoker').apply(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Fri</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>91</th>\n",
       "      <td>22.49</td>\n",
       "      <td>3.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.155625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>22.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>No</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>90</th>\n",
       "      <td>28.97</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>40.17</td>\n",
       "      <td>4.73</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.117750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sat</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>59</th>\n",
       "      <td>48.27</td>\n",
       "      <td>6.73</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.139424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>48.33</td>\n",
       "      <td>9.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.186220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>102</th>\n",
       "      <td>44.30</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>50.81</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.196812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sun</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>112</th>\n",
       "      <td>38.07</td>\n",
       "      <td>4.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>48.17</td>\n",
       "      <td>5.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>6</td>\n",
       "      <td>0.103799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>184</th>\n",
       "      <td>40.55</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>45.35</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.077178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Thur</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>85</th>\n",
       "      <td>34.83</td>\n",
       "      <td>5.17</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>4</td>\n",
       "      <td>0.148435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>41.19</td>\n",
       "      <td>5.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>5</td>\n",
       "      <td>0.121389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>83</th>\n",
       "      <td>32.68</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.152999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>43.11</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>4</td>\n",
       "      <td>0.115982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_bill    tip smoker   day    time  size   tip_pct\n",
       "day  smoker                                                            \n",
       "Fri  No     91        22.49   3.50     No   Fri  Dinner     2  0.155625\n",
       "            94        22.75   3.25     No   Fri  Dinner     2  0.142857\n",
       "     Yes    90        28.97   3.00    Yes   Fri  Dinner     2  0.103555\n",
       "            95        40.17   4.73    Yes   Fri  Dinner     4  0.117750\n",
       "Sat  No     59        48.27   6.73     No   Sat  Dinner     4  0.139424\n",
       "            212       48.33   9.00     No   Sat  Dinner     4  0.186220\n",
       "     Yes    102       44.30   2.50    Yes   Sat  Dinner     3  0.056433\n",
       "            170       50.81  10.00    Yes   Sat  Dinner     3  0.196812\n",
       "Sun  No     112       38.07   4.00     No   Sun  Dinner     3  0.105070\n",
       "            156       48.17   5.00     No   Sun  Dinner     6  0.103799\n",
       "     Yes    184       40.55   3.00    Yes   Sun  Dinner     2  0.073983\n",
       "            182       45.35   3.50    Yes   Sun  Dinner     3  0.077178\n",
       "Thur No     85        34.83   5.17     No  Thur   Lunch     4  0.148435\n",
       "            142       41.19   5.00     No  Thur   Lunch     5  0.121389\n",
       "     Yes    83        32.68   5.00    Yes  Thur   Lunch     2  0.152999\n",
       "            197       43.11   5.00    Yes  Thur   Lunch     4  0.115982"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argument to a function passed to 'apply' are supplied as keyword-value\n",
    "\n",
    "tips.groupby(['day','smoker']).apply(top_n, n=2, column='total_bill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupBy Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>151.0</td>\n",
       "      <td>0.159328</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.056797</td>\n",
       "      <td>0.136906</td>\n",
       "      <td>0.155625</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>0.291990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.163196</td>\n",
       "      <td>0.085119</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.195059</td>\n",
       "      <td>0.710345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count      mean       std       min       25%       50%       75%  \\\n",
       "smoker                                                                      \n",
       "No      151.0  0.159328  0.039910  0.056797  0.136906  0.155625  0.185014   \n",
       "Yes      93.0  0.163196  0.085119  0.035638  0.106771  0.153846  0.195059   \n",
       "\n",
       "             max  \n",
       "smoker            \n",
       "No      0.291990  \n",
       "Yes     0.710345  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tips.groupby('smoker')['tip_pct'].describe()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       smoker\n",
       "count  No        151.000000\n",
       "       Yes        93.000000\n",
       "mean   No          0.159328\n",
       "       Yes         0.163196\n",
       "std    No          0.039910\n",
       "       Yes         0.085119\n",
       "min    No          0.056797\n",
       "       Yes         0.035638\n",
       "25%    No          0.136906\n",
       "       Yes         0.106771\n",
       "50%    No          0.155625\n",
       "       Yes         0.153846\n",
       "75%    No          0.185014\n",
       "       Yes         0.195059\n",
       "max    No          0.291990\n",
       "       Yes         0.710345\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unstack('smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>24.71</td>\n",
       "      <td>5.85</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.236746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>20.69</td>\n",
       "      <td>5.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>5</td>\n",
       "      <td>0.241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10.29</td>\n",
       "      <td>2.60</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.252672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>7.51</td>\n",
       "      <td>2.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.266312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>11.61</td>\n",
       "      <td>3.39</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>14.31</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>23.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>9.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip smoker   day    time  size   tip_pct\n",
       "88        24.71  5.85     No  Thur   Lunch     2  0.236746\n",
       "185       20.69  5.00     No   Sun  Dinner     5  0.241663\n",
       "51        10.29  2.60     No   Sun  Dinner     2  0.252672\n",
       "149        7.51  2.00     No  Thur   Lunch     2  0.266312\n",
       "232       11.61  3.39     No   Sat  Dinner     2  0.291990\n",
       "109       14.31  4.00    Yes   Sat  Dinner     2  0.279525\n",
       "183       23.17  6.50    Yes   Sun  Dinner     4  0.280535\n",
       "67         3.07  1.00    Yes   Sat  Dinner     1  0.325733\n",
       "178        9.60  4.00    Yes   Sun  Dinner     2  0.416667\n",
       "172        7.25  5.15    Yes   Sun  Dinner     2  0.710345"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.groupby('smoker', group_keys=False).apply(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---|||\n",
    "### Pivot Tables and Cross-Tabulation\n",
    "\n",
    "Data Summarization tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
